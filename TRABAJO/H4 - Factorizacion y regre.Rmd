---
output: html_document
editor_options: 
  chunk_output_type: inline
---


```{r}
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/basefinal.csv'
subdata = import(link)
summary(subdata)
row.names(subdata)=subdata$Pais
```

###variable numerica
```{r}

library(car)
subdata$Autonomia=recode(subdata$Autonomia,"0=1;0.25=2;0.5=3;0.75=4;1=5")

table(subdata$Autonomia )
```

###Variable violencia
```{r}
#Le asignamos etiquetas a los valores
subdata$Violencia=recode(subdata$Violencia,"0.25=1;0.5=2;0.75=3;1=4")

table(subdata$Violencia)
```
- ELIMINAR LA VARIABLES DEPENDIENTE
###multiplicamos el indice por 100
```{r}
subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero 
subdata$Autonomia= 100 - subdata$Autonomia
subdata$Violencia= 100 - subdata$Violencia 
#subdata$Desempleo= 100 - subdata$Desempleo


```

###Resumen de data
```{r}
str(subdata)
```

1. Calculemos matriz de correlación:

```{r}
#scale(subdata$Desempleo,scale = T)*100

dontselect=c("Pais","Desempleo")
select=setdiff(names(subdata),dontselect) 
thesubdata=subdata[,select] # sin nombre de país.

# esta es:
#thesubdata=na.omit(thesubdata)
library(polycor)
corMatrix=polycor::hetcor(thesubdata)$correlations
```
2. Explorar correlaciones:
```{r}
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
```

```{r}
#Evaluando significancia:
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix),
          insig = "blank")
```
```{r}
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
```

Si puedes ver bloques correlacionados, hay esperanza de un buen analisis factorial. ¿?

3. Verificar si datos permiten factorizar:
```{r}
library(psych)
psych::KMO(corMatrix)
```
4. Verificar si la matriz de correlaciones es adecuada
    - Aqui hay dos pruebas:

 a. Hnula: La matriz de correlacion es una matriz identidad
```{r}
cortest.bartlett(corMatrix,n=nrow(thesubdata))$p.value>0.05
```
 b. Hnula: La matriz de correlacion es una matriz singular.
```{r}
library(matrixcalc)
is.singular.matrix(corMatrix)
```

5, Determinar en cuantos factores o variables latentes podríamos redimensionar la subdata:
```{r}
fa.parallel(thesubdata,fm = 'ML', fa = 'fa')
```

6. Redimensionar a numero menor de factores

Resultado inicial:
```{r}
library(GPArotation)
resfa <- fa(thesubdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
```

```{r}
print(resfa$loadings)
```

Resultado mejorado:
```{r}
print(resfa$loadings,cutoff = 0.5)
```
Cuando logramos que cada variable se vaya a un factor, tenemos una estructura simple.

Resultado visual:
```{r}
fa.diagram(resfa)
```

7. 0Evaluando Resultado obtenido:
```{r}
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
```
```{r}
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
```
```{r}
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
```
```{r}
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
```
```{r}
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
```

8.Posibles valores proyectados:
```{r}
#¿Qué nombres les darías?
as.data.frame(resfa$scores)%>%head()
```

```{r}
HappyDemoFA=cbind(HappyDemo[1],as.data.frame(resfa$scores))

library(plotly)


plot_ly(data=HappyDemoFA, x = ~MR1, y = ~MR2, z = ~MR3, text=~Country) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Demo'),
                     yaxis = list(title = 'Tranquilidad'),
                     zaxis = list(title = 'Bienestar')))

```

RECORDANDO:

```{r}
library(fpc)
library(cluster)
library(dbscan)
# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]

g.dist.cmd = daisy(HappyDemoFA[,c(2:4)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
abline(h=0.63,col='red')
```

Para tener una idea de cada quien:
```{r}
resDB=fpc::dbscan(g.dist.cmd, eps=0.63, MinPts=3,method = 'dist')
HappyDemoFA$clustDB=as.factor(resDB$cluster)
aggregate(cbind(MR1, MR2,MR3) # dependientes
          ~ clustDB, # nivel
          data = HappyDemoFA,    # data
          max)            # operacion
```

```{r}
plot_ly(data=HappyDemoFA, x = ~MR1, y = ~MR2, z = ~MR3, text=~Country, color = ~clustDB) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Demo'),
                     yaxis = list(title = 'Tranquilidad'),
                     zaxis = list(title = 'Bienestar')))
```

Finalmente, veamos relaciones:
```{r}
library(BBmisc)
HappyDemo$faDemo=normalize(HappyDemoFA$MR1, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 10))

HappyDemo$faHappyInd=normalize(HappyDemoFA$MR2, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 10))

HappyDemo$faHappySoc=normalize(HappyDemoFA$MR3, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 10))
```

You can see them all here:
```{r}
plot(HappyDemo[,c("ScoreDemo","ScoreHappy","faDemo","faHappyInd",
                  "faHappySoc")])

```














```{r}
hipotesis = formula(DesigualdadGenero ~ .)
#como son todas las demas las v. independientes se pone "."

regre=lm(hipotesis,data=subdata[,-c(1)])
summary(regre)
```
- lo interesante es que libertad de movimeinto, VIOLENCIA y Acceso a justucua

- tmb es interesante ver que este modelo explica un 8% es muy alto

```{r}
hipotesis1 = formula(DesigualdadGenero ~ Autonomia + VozPolitica + Desempleo + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre1=lm(hipotesis1,data=subdata[,-c(1)])
summary(regre1)
```
SI QUITAMOS LOS 3 anteriores su explicacion baja

```{r}
hipotesis2 = formula(DesigualdadGenero ~ Autonomia+ VozPolitica  + LibertadMov + Desempleo + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre2=lm(hipotesis2,data = subdata[,-c(1)])
summary(regre2)
```
- este modelo 2 explica ma´s que quitando todo


```{r}
hipotesis3 = formula(DesigualdadGenero ~ Autonomia+ VozPolitica  + LibertadMov + Desempleo + AccesoJ + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre3=lm(hipotesis3,data = subdata[,-c(1)])
summary(regre3)
```

- expñica mas todas las variables menos Violencia

```{r}
hipotesis4 = formula(DesigualdadGenero ~ Autonomia+ VozPolitica + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre4=lm(hipotesis4,data=subdata[,-c(1)])
summary(regre4)
```
```{r}
hipotesis2 = formula(DesigualdadGenero ~ Autonomia  + LibertadMov + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre2=lm(hipotesis2,data=subdata[,-c(1)])
summary(regre2)
```
- se le quita la variable desempleo y vozpolitica

```{r}
hipotesis2 = formula(DesigualdadGenero ~ Autonomia + CuentaF)
#como son todas las demas las v. independientes se pone "."

regre2=lm(hipotesis2,data=subdata[,-c(1)])
summary(regre2)
```

DIAGNOSTICO DE LA REGRESION

  - Para que se considere que el modelo de regresión elegido es el adecuado, debemos verificar algunos 
    requisitos a posteriori:

1. Linealidad:
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(regre, 1)

```
2. Homocedasticidad

  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(regre, 3)
```

También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# null: modelo homocedastico
bptest(regre)
```

  - La probabilidad de homocedasticidad es muy baja (p-value menor a 0.05), de ahi que se rechaza que el modelo
    muestre homocedasticidad.

3. Normalidad de los residuos

Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(regre, 2)

```

Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(regre$residuals)
```

4. No multicolinelidad

  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(regre) # > 5 es problematico
```
Normalmente le prestamos atencion al indice de Cook y a los valores predecidos (los hat values):
```{r}
checkRegre[checkRegre$cook.d |checkRegre$hat]
```

