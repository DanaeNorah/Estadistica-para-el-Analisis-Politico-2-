

PRACTICA CALIFICADA 5  - 20180267                                                               

PASO 0: solicito paquetes
```{r}
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas 
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
```

PASO 1: scrapeo la data

```{r}
url1= "https://en.wikipedia.org/wiki/World_Happiness_Report" 

happiness =htmltab(doc = url1, 
              which = '//*[@id="mw-content-text"]/div[1]/table',
              encoding = "UTF-8") 
```

PASO 2: limpiamos y preparamos la base de datos "happines"
```{r}
#a.Eliminamoslas columnas Overall y Score
happiness[c(1,3)]=NULL

#Limpio columna Country or region
happiness$`Country or region`=gsub('Â','',happiness$`Country or region`)
happiness$`Country or region`=trimws(happiness$`Country or region`,whitespace = "[\\h\\v]")

head(happiness$`Country or region`)

#b.Cambio los nombres para hacer la data más sencilla
names(happiness)[1]='Country'
names(happiness)[2]='GDP'
names(happiness)[3]='SSupport'
names(happiness)[4]='Healthy'
names(happiness)[5]='Freedom'
names(happiness)[7]='Corruption'

#c. compruebo qeu no existen espacios en blanco
head(names(happiness))

#d.compruebo que sean numericos
str(happiness)
happiness[,c(2:7)]=lapply(happiness[,c(2:7)], as.numeric)
str(happiness)

#cambio a row.names y elimino la columna country
row.names(happiness)=happiness$Country
happiness$Country= NULL
str(happiness)

##para agilizar copio y la nombro "subdata"
subdata<-happiness
#e. omito los valores perdido
subdata<-na.omit(subdata)
```

PARA RESPONDER LA PREGUNTA 2

#a. Aplicando los comandos necesarios, ¿cuántos grupos se recomienda para el caso de clúster particionante? ¿Y para clústers jerárquicos?

PASO 3: IDENTIFICAR EL NUMERO DE CLUSTER
```{r}
#CALCULAMOS LAS DISTANCIAS CON DAYSY
g.dist = daisy(subdata, metric="gower")

#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)

#Número de clusters para JERARQUIZACION (colocamos hcut)
fviz_nbclust(subdata, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
```

RESPUESTA: Para el cluster particionante me quedo con 7 grupos. Paea los clusters jerarquicos me quedo con 5 gurupso. Debido a que, la linea punteada que sale en los graficos me indica la cantidad de clusters. Asismismo, entre los dos me quedaria con el menor que es 5.

#b.	Realice una evaluación gráfica de pam, agnes y diana. ¿Cuál de estas es la más indicada? ¿Por qué?

PASO 4: GRÁFICOS DE SILUETAS PARA VISUALIZAR LA MEJOR OPCIÓN DE CLUSTERIZACIÓN
```{r}
particion = pam(g.dist,5,cluster.only = F) 
aglomerativo = hcut(g.dist, k = 5,hc_func='agnes',hc_method = "ward.D")
divisivo = hcut(g.dist, k = 5,hc_func='diana')
```

PASO5: En base a estas listas podemos calcular los gráficos de siluetas. 

```{r}
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
```
Respuesta: La mas indicada es el pam o particion, porque su widht es el más alto (0.25)
 

PARA RESPONDER LA PREGUNTA 3

PASO 6: CLUSTER DE DENSIDAD

```{r}
#Generamos el escalamiento usanto las distancias calculadas. Es decir el g.dist
proyeccion = cmdscale(g.dist, k=2,add = T) #k es el número de dimensiones solicitadas
#Creamos una nueva columna en nuestra data que sea la primera dimensión
subdata$dim1 <- proyeccion$points[,1]
#Creamos una nueva columna en nuestra data que sea la segunda dimensión
subdata$dim2 <- proyeccion$points[,2]
```

PASO 7: Graficamos en base a las dimensiones calculadas. 

```{r}
#GRAFICANDO (REPASAR GGPLOT!!)

base= ggplot(subdata,aes(x=dim1, y=dim2,label=row.names(subdata))) 
base + geom_text(size=2)#aes=ejes, labels=etiquetas

#Coloreando el mapa

##Creemos primero las columnas 
subdata$c.particion=as.factor(particion$clustering)
subdata$c.aglomerativo=as.factor(aglomerativo$cluster)
subdata$c.divisivo=as.factor(divisivo$cluster) ###se vuelve factor para poder colorearlos, porque estaban numericas

##Estimando límites
min(subdata[,c('dim1','dim2')]); max(subdata[,c('dim1','dim2')])
```
#a.	¿Cuáles son los valores máximo y mínimo de los límites? 
RESPUESTA: el valor minimo es: -0.5246144. Y el valor maximo es: 0.5498226



```{r}
#GRAFICAS PARA PAM, AGNES Y DIANA

limites=c(-0.53,0.55) #Estos límites deben incluir los números obtenidos con el comando anterior

base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()

base + geom_point(size=2, aes(color=c.particion))  + labs(title = "PARTICIONANTE") 
base + geom_point(size=2, aes(color=c.aglomerativo)) + labs(title = "AGLOMERATIVO")
base + geom_point(size=2, aes(color=c.divisivo)) + labs(title = "DIVISIVO")
```

Ahora utilizamos la agrupación por densidad

```{r}
#Calculando nuevas distancias (euclideandas) utilizando las dimensiones creadas anteriormente. 
g.dist.cmd = daisy(subdata[,c('dim1','dim2')], metric = 'euclidean')

#CALCULANDO EL EPSilon. Tenemos que ver en qué parte la curva eleva su ángulo drásticamente. 

library(dbscan)
kNNdistplot(g.dist.cmd, k=6) # Consideramos 5 como el número mínimo de vecinos (puntos)
abline(h=0.15, lty=2)

# Generamos la agrupación de densidada, es decir, una lista con información así como las otras estrategias. 
install.packages("fpc")
library(fpc)
db.cmd = dbscan(g.dist.cmd, eps=0.15, MinPts=6, method = 'dist')
db.cmd 

# Creamos una columna llamada c.densidad con el vector cluster.
subdata$c.densidad=as.factor(db.cmd$cluster)

#GRAFICANDO

install.packages("ggrepel")
library(ggplot2)
library(ggrepel)
base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
dbplot= base + geom_point(aes(color=c.densidad)) 
dbplot

#graficando con texto de los casos. No sirve cuando son muchos casos. 
dbplot + geom_text_repel(size=5,aes(label=row.names(subdata)))


#Se puede solicitar el gráfico sólo resaltando aquellos atípicos que no están en ningún grupo o cluster creado. 
LABEL=ifelse(subdata$c.densidad==0,row.names(subdata),"")
dbplot + geom_text_repel(aes(label=LABEL),
                         size=5, 
                         direction = "x", ylim = 0.45,
                         angle=45,
                         segment.colour = "grey")
```

#b.	¿Cuántos clústers obtenemos? ¿Cuántos casos no se pueden clusterizar?

RESPUESTA: 
- el total de clusters es 156 por la tabla de dbscan
-Analizando la grafica, los casos que no se pueden clusterizar con 3 ( Rwanda y Solmalia). Asimismo, analizando la tabla de dbscan son dosgrupos que no fueron clasificados porque estan en la columna 0.









