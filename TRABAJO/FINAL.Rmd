---
title: "ESTADÍSTICA"
output: html_notebook
---

```{r}
library(htmltab)
library(stringr) 
library(readr)
library(rio)
library(tidyr)
```

BASE DE DATOS DE LA OCDE LIBERTADES CIVILES 
(VARIABLE 1: Political Voice) (Practice)
(VARIABLE 2: Freedom of movement) (Practice)

##PRESENTACION DE DATOS:

1. LIMPIEZA DE DATOS INDICE DESIGUALDAD DE GENERO  (Variable dependiente)

NOTA: La siguiente base de datos fue encontrada en la página web de United Nations Development Programme que permite descargar la información en formato "csv". Luego la data fue subida a mi repositorio personal de GitHub con el nombre de "index.csv" para poder importarla desde ahí.

Paso 1: Importamos base de datos 1
```{r}
#Abrimos library rio
library(rio)

#Vamos a importar la base desde GitHub
#Creamos el objeto linkindex
linkindex="https://raw.githubusercontent.com/mercy-diaz/ProyectoEst/master/Bases%20originales/index.csv"

#Usamos la función import para traer la data
#A la base le asignamos el nombre "index"
index=import(linkindex)

#Usamos funcion str para revisar la data
str(index)
```

Paso 2: Nos quedamos solo con las columnas que vamos a utilizar
```{r}
index=index[,c(2,25)]
```

Paso 3: Cambiamos los nombres de las columnas
```{r}
names(index)[2]="Gii2018"
```

Paso 4: Revisamos las columnas que tenemos:

Empezamos con columna "Country"
```{r}
#Nos aseguramos de que los nombres de los países estén limpios
index$Country
```

Limpiamos los nombres en columna "Country"
```{r}
#Aplicamos la función gsub para reemplazar los símbolos no deseados
index$Country = gsub("CÃ´te d'Ivoire","Côte d'Ivoire",index$Country)
```

Verificamos:
```{r}
index$Country
```

Continuamos con la columna "Gii2018"
```{r}
#Observamos que tiene elementos no deseados ("") que debemos eliminar
str(index$Gii2018)
```

Limpiamos la columna "Gii2018"
```{r}
#En este caso podemos usar la función str_split
#Primero abrimos library stringr
library(stringr)

#Revisamos en qué partición está el dato que nos interesa
str_split(string = index$Gii2018,
          pattern = '\\"',
          simplify = T)
#El dato se encuentra en la partición 2

#Creamos una nueva columna "GII"
index$GII = str_split(string = index$Gii2018,
          pattern = '\\"',
          simplify = T)[,2]
```

Revisamos la nueva columna GII
```{r}
#Observamos que está limpia
str(index$GII)

#Ahora la información deber ser convertida a valores numéricos
index$GII = as.numeric(index$GII)
```

```{r}
#Aplicamos función str para revisar la columna GII
str(index$GII)
#Ahora es numérica

#Cambiamos el nombre
names(index)[3]="DesigualdadGenero"
```

Paso 5: Nos quedamos con las columnas que vamos a usar
```{r}
index = index[,c(1,3)]
```

NOTA: La base original de donde se recogieron las variables independientes fue encontrada en la página web de Organisation for Economic Co-Operation and Development (OECD) que permite descargar la información en formato "csv". Luego la data fue subida a mi repositorio personal de GitHub con el nombre de "GIDDB2019Completa.csv" y está incluida como referencia dentro de la carpeta "Bases originales". En el link fuente donde está ubicada la data existe la opción que permite personalizar la búsqueda y descargar solo las variables que se requieren. De ahí se obtuvieron las bases de datos 2 (autreprod) y 3 (violencia) que también están en la carpeta. Esas dos fueron las bases usadas para el procesamiento de datos que viene a continuación


2. Limpieza base de datos Autonomía Reproductiva:

Paso 1: Importamos la base de datos 2
```{r}
#No es necesario abrir library rio nuevamente

#vamos a importar la base desde GitHub
#Creamos el objeto linkautreprod
linkautreprod="https://raw.githubusercontent.com/mercy-diaz/ProyectoEst/master/Bases%20originales/autreprod.csv"

#Usamos la función import para traer la data
#A la base le asignamos el nombre "autreprod"
autreprod=import(linkautreprod)

#Usamos funcion str para revisar la data
str(index)
```

Paso 2: Nos quedamos con las columnas que vamos a utilizar
```{r}
autreprod = autreprod[,c(4,11)]
```

Paso 3: Cambiamos el nombre de la columna
```{r}
names(autreprod)[2] = "MLAutonomia"
```

Paso 4: Revisamos y eliminamos valores duplicados
```{r}
#Aplicamos función duplicated
autreprod[duplicated(autreprod),]
autreprod = autreprod[!duplicated(autreprod),]
```

Paso 5: Revisamos las columnas que tenemos:

Empezamos con la columna "Country"
```{r}
#Nos aseguramos de que los nombres de los países esten limpios
autreprod$Country
#Observamos que se debe hacer una corrección
```

Limpiamos la columna "Country"
```{r}
#Aplicamos la funcion gsub para reemplazar los símbolos no deseados
autreprod$Country = gsub("CÃ´te d'Ivoire","Côte d'Ivoire",autreprod$Country)
```

Verificamos:
```{r}
autreprod$Country
```


3. Limpieza de base de datos Violencia contra la mujer

Paso 1: Importamos la base de datos 3
```{r}
#No es necesario abrir library rio nuevamente

#Vamos a importar la data desde GitHub
#Creamos el objeto linkviolencia
linkviolencia="https://raw.githubusercontent.com/mercy-diaz/ProyectoEst/master/Bases%20originales/violencia.csv"

#Usamos la función import para traer la data
#A la base le asignamos el nombre "violenciamuj"
violenciamuj=import(linkviolencia)

#Usamos función str para revisar la data
str(violenciamuj)
```

Paso 2: Nos quedamos con las columnas que vamos a utilizar
```{r}
violenciamuj = violenciamuj[,c(4,11)]
```

Paso 3: Cambiamos el nombre de la columna
```{r}
names(violenciamuj)[2] = "MLViolencia"
```

Paso 4: Revisamos y eliminamos valores duplicados
```{r}
#Aplicamos funcion duplicated
violenciamuj[duplicated(violenciamuj),]
violenciamuj = violenciamuj[!duplicated(violenciamuj),]
```

Paso 5: Revisamos las columnas que nos quedaron:

Empezamos con la columna "Country"
```{r}
#Nos aseguramos de que los nombres de los países estén limpios
violenciamuj$Country
#Observamos que se debe hace una corrección
```

Limpiamos la columna "Country"
```{r}
#Aplicamos la función gsub para reemplazar
violenciamuj$Country = gsub("CÃ´te d'Ivoire","Côte d'Ivoire",violenciamuj$Country)
```

Revisamos nuevamente
```{r}
str(violenciamuj)
```



4. LIMPIEZA DE LA BASE DE DATOS VOZ POLITICA:

PASO 1: Abrir nuestra base de datos original
```{r}
link_github="https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/Political_voice_(original).csv"
Politica=import(link_github)
```

PASO 2: Eliminamos los duplicadoS:
```{r}
Politica=Politica[-grep("ALL",Politica$REGION),]
```

PASO 3: Eliminados las columnas que no necesitaremos:
```{r}
Politica=Politica[,-grep("REGION|Region|LOCATION|INC|Income|VAR|TIME|Year|Flags|Flag Codes",names(Politica))]
```

PASO 4:Verificamos que sean numericos los valores:
```{r}
str(Politica$Value)
```
PASO 5: Eliminamos los "law" en las filas de nuestra data "Politica" 
```{r}
Politica = Politica[Politica$Variable=="Practice",]
```

PASO 6: Cambiamos el nombre de la tercera columna de nuestra data "Politica"
```{r}
names(Politica)[3]="VozPolitica"
head(Politica)
```


5. LIMPIEZA DE LA BASE DE DATOS LIBERTAD DE DE MOVIMIENTO:

PASO 1: Abrir nuestra base de datos original de nuestro Git Hub:
```{r}
link1_github="https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/Freedom%20_(original).csv"
freedom =import(link1_github)
```

PASO 2: Eliminamos los duplicados de nuestra data:
```{r}
freedom=freedom[-grep("ALL",freedom$REGION),]
```

PASO 3: Eliminados las columnas que no utilizaremos:
```{r}
freedom=freedom[,-grep("REGION|Region|LOCATION|INC|Income|VAR|TIME|Year|Flags|Flag Codes",names(freedom))]
```

PASO 4: Verificamos que sean numericos los valores:
```{r}
str(freedom$Value)
```

PASO 5: Eliminamos los "law" en las filas de nuestra data "freedom"
```{r}
freedom = freedom[freedom$Variable=="Practice",]
```

PASO 6: Cambiamos el nombre de la tercera columna de nuestra data "freedom"
```{r}
names(freedom)[3]="LibertadMov"
head(freedom)
```

6. LIMPIEZA DE LA BASE DE DATOS DE LA VARIABLE DESCONFIANZASJ:

```{r}
library(rio)

AccesoJ="https://github.com/GabiCorazao/EstS2/raw/Trabajo/Acceso-Justicia(original).csv"
AccesoJ=import(AccesoJ)

names(AccesoJ)
```

Limpiar la data

Buscando las filas y columnas que no deben estar incluidos

```{r}
?grep
AccesoJ[grep("ALL",AccesoJ$REGION),]

?grep
AccesoJ[,grep("REGION|Region|LOCATION|INC|Income|VAR|TIME|Year|Flags|Flag Codes",names(AccesoJ))]

```

Eliminando los datos que no deben estar incluidos

```{r}
AccesoJ=AccesoJ[-grep("ALL",AccesoJ$REGION),]
AccesoJ=AccesoJ[,-grep("REGION|Region|LOCATION|INC|Income|VAR|TIME|Year|Flags|Flag Codes",names(AccesoJ))]
```

Tambien se van a eliminar las filas que corresponden a la variable "LAW"

```{r}
?grep
AccesoJ[grep("Law",AccesoJ$Variable),]

AccesoJ=AccesoJ[-grep("Law",AccesoJ$Variable),]

#Ya que esta hecho, voy a quitar la columna variables y voy a renonmbrar la columna "Value"
AccesoJ=AccesoJ[,-grep("Variable",names(AccesoJ))]

#cambiando el nombre
names(AccesoJ) = c("Country", "DesconfianzaSJ")

```

Verificar si hay datos duplicados
```{r}
AccesoJ[duplicated(AccesoJ$Country),]
AccesoJ=AccesoJ[!duplicated(AccesoJ$Country),]
```

Verificamos si los valores son leidos como numeros o como caracteres
```{r}
str(AccesoJ)
#como es leido como numerico, ya no hace falta formatear nada
```


7. LIMPIEZA DE LA BASE DE DATOS DE LA VARIABLE SECUNDARIA COMPLETA:
PASO 1: Traemos la data
```{r}
library(rio)

SecundariaC="https://github.com/GabiCorazao/EstS2/blob/Trabajo/Secundaria-Completa(original).xlsx?raw=true"
SecundariaC=import(SecundariaC)

names(SecundariaC)
```

PASO 2: Quitar algunas filas y columnas que he identificado que no me sirven

```{r}
#identificando las filas que no me sirven
SecundariaC$`Table 5. Gender Inequality Index`

#eliminando las filas y columnas que no me sirven
SecundariaC=SecundariaC[-c(1:7, 70, 125, 163, 200, 207:263),]
SecundariaC=SecundariaC[,-c(1,3:12,14:20)]

```

PASO 3: Renombrar mis columnas 
```{r}
names(SecundariaC) = c("Country", "SecundariaCompleta")

#y voy a verificar que funcionen y revisar de nuevo si hay alguna unidad que deba ser limpiada
SecundariaC$Country
```

PASO 4: Verificar si los datos se leen como numericos
```{r}
str(SecundariaC)

#tenemos que convertir a numericos los datos de la segunda columna 
SecundariaC$SecundariaCompleta=as.numeric(SecundariaC$SecundariaCompleta)

#verificamos
str(SecundariaC)
```
Pd:Antes de convertir los datos a numerico habian como 14 decimales(si no mas) y despues de aplicar el codigo resultaron solo 7 decimales.



8. LIMPIEZA DE LA BASE DE DATOS DE LA VARIABLE DESEMPLEO MUJER:

PASO 1: Abrir nuestra base de datos original de nuestro Git Hub:
```{r}
library(rio)
#Variable: "Tasa total de desempleo mujer"

link2="https://github.com/Winny-calderon/Proyecto-EAP2/raw/master/hdro_statistical_data_dashboard_2.xlsx"
gender_gap=import(link2)
names(gender_gap)
```

PASO 2: Elminamos las columnas y filas que no nos son de utilidad:
```{r}
#columnas
gender_gap=gender_gap[,-c(1, 3:10)]
gender_gap=gender_gap[,-c(2:5)]
gender_gap=gender_gap[,-c(3:13)]

#filas:
gender_gap=gender_gap[-c(1:14, 77, 132, 170, 207, 214:272),]

```

PASO 3: Cambiar el nombres de las columnas:
```{r}
names(gender_gap) = c("Country", "DesempleoMuj")

```

PASO 4: Configuracion de nuestras variables:
```{r}
str(gender_gap)
#En el caso de "Country" no hay que corregir
#La tasa de desempleo está en caracter, debemos convertirla a numérica
gender_gap$DesempleoMuj = as.numeric(gender_gap$DesempleoMuj)
```



9. LIMPIEZA DE LA BASE DE DATOS Mujeres CON CUENTA FINANCIERA INSTITUCIONAL O CON SERVICIOS DE DINERO MOVIL:

PASO 1: Abrir nuestra base de datos original de nuestro Git Hub:
```{r}
#Variable: "Mujeres con cuenta financiera institucional o con servicios de  dinero movil"
link1= "https://github.com/Winny-calderon/Proyecto-EAP2/raw/master/hdro_statistical_data_dashboard_3.xlsx"
data_woman=import(link1)
names(data_woman)
```

PASO 2: Eliminar columnas y filas 
```{r}
#eliminamos columnas
data_woman=data_woman[,-c(1, 3:24, 26:28)]

#eliminamos filas
data_woman=data_woman[-c(1:12, 75, 130, 168, 205, 212:267),]
```

PASO 3: Cambiar los nombres de las columnas:
```{r}
names(data_woman) = c("Country", "CuentaF")
```

PASO 4: Configuracion de cada variable:
```{r}
str(data_woman) 

#"Account" aparece como caracter, por ende, debemos convertirla a numerica
data_woman$CuentaF = as.numeric(data_woman$CuentaF)
```

##MERGE DE NUESTRAS BASES DE DATOS

1. MERGE  DE AUTONOMIA Y VIOLENCIA

Paso 1: Ahora que ya hemos limpiado las bases vamos a hacer el merge una por una
```{r}
#Empezamos con bases 2 y 3
#Para fusionar usamos función merge
base1=merge(autreprod,violenciamuj,by.x = "Country",by.y = "Country")
#De esta forma incluimos todos nuestros casos
#Presupone que la primera columna será la columna guía
```

Revisamos
```{r}
base1$Country
```

Modificamos algunos nombres para que la información se incorpore mejor
```{r}
base1$Country = gsub('Bolivia',"Bolivia (Plurinational State of)",base1$Country)
base1$Country = gsub('Democratic Republic of the Congo',"Congo (Democratic Republic of the)",base1$Country)
```


2. MERGE DE NUESTRA BASE 1 CON DESIGUALDAD:
```{r}
autonomia=merge(base1,index,by.x = "Country",by.y = "Country")
```

Limpiamos espacios en blanco en nombres de observaciones
```{r}
#Usamos la función trimws
autonomia$Country=trimws(autonomia$Country,whitespace = "[\\h\\v]")
```

Revisamos el data frame
```{r}
data.frame(autonomia)
```

Buscamos casos duplicados
```{r}
autonomia[duplicated(autonomia$Country),]
autonomia[!complete.cases(autonomia),]
```


3. MERGE DE POLITICA Y FREEDOM

PASO 1: Empleamos la funcion merge
```{r}
libertad=merge(Politica,freedom,by.x = "Country",by.y="Country")
head(libertad)
```
PASO 2: Eliminamos las columnas que no usaremos
```{r}
libertad=libertad[,c(-2,-4)]
```

4. MERGE DE DESCONFIANZASJ Y SECUNDARIA  COMPLETA

PASO 1: Realizamos el Merge 
```{r}
Acceso_Secundaria=merge(AccesoJ,SecundariaC,all.x=T,all.y=T)

Acceso_Secundaria[!complete.cases(Acceso_Secundaria),] 
```

PASO 2: Modificamos los nombres de paises que no estan iguales en ambas bases de datos 
```{r}
#AccesoJ
AccesoJ[AccesoJ$Country=="CÃ´te d'Ivoire","Country"]="Côte d'Ivoire"
AccesoJ[AccesoJ$Country=="Chinese Taipei","Country"]="China"
AccesoJ[AccesoJ$Country=='Palestinian Authority or West Bank and Gaza Strip',"Country"]="Palestine, State of"

#SecundariaC
SecundariaC[SecundariaC$Country=='Bolivia (Plurinational State of)',"Country"]="Bolivia"
SecundariaC[SecundariaC$Country=='Czechia',"Country"]="Czech Republic"
SecundariaC[SecundariaC$Country=='Congo (Democratic Republic of the)',"Country"]="Democratic Republic of the Congo"
SecundariaC[SecundariaC$Country=='Hong Kong, China (SAR)',"Country"]="Hong Kong, China"
SecundariaC[SecundariaC$Country=='Iran (Islamic Republic of)',"Country"]="Iran"
SecundariaC[SecundariaC$Country=='Moldova (Republic of)',"Country"]="Moldova"

SecundariaC[SecundariaC$Country=='Russian Federation',"Country"]="Russia"
SecundariaC[SecundariaC$Country=='Slovakia',"Country"]="Slovak Republic"
SecundariaC[SecundariaC$Country=='South Sudan',"Country"]="South Sudan"
SecundariaC[SecundariaC$Country=='Tanzania (United Republic of)',"Country"]="Tanzania"
SecundariaC[SecundariaC$Country=='Venezuela (Bolivarian Republic of)',"Country"]="Venezuela"
```

PASO 3: Hacemos el merging nuevamente
```{r}
sec=merge(AccesoJ,SecundariaC,all.x=T,all.y=T)
```


5. MERGE DE DESEMPLEO Y CUENTA FINANCIERA:
PASO 1: Empleamos la funcion MERGE
```{r}
#Primero veamos el nombre de las variables
names(gender_gap)
names(data_woman)

#entonces le pedimos que nos fusione las datas en base a la variable comun (o Key): Country
#gender_data: será nuestra nueva base de datos, la cual será contendrá a nuestras dos bases editadas antes
gender_data=merge(gender_gap,data_woman,by.x='Country', by.y='Country') 
head(gender_data)
```

PASO 2: Ver los paises totales
```{r}
gender_data2=merge(gender_gap,data_woman,all.x=T,all.y=T)
```
Podemos notar que todos los casos de países conicide, es decir, no hay ningún pais mas ni menos en las dos datas usadas antes.

PASO 3: fijarnos si hay duplicados en nuestra data:
```{r}
gender_data[duplicated(gender_data$Country),]
```
No hay ninguna columna duplicada.

PASO 4: Editar los nombres a los paises. Esto para que nuestra data sea mas limpia y ordenada.
```{r}
#Bolivia (Plurinational State of)
gender_data[gender_data$Country=='Bolivia (Plurinational State of)',"Country"]="Bolivia"
#Congo (Democratic Republic of the)
gender_data[gender_data$Country=='Congo (Democratic Republic of the)',"Country"]="Congo, Democratic Republic of the"
#Eswatini (Kingdom of)
gender_data[gender_data$Country=='Eswatini (Kingdom of)',"Country"]="Eswatini, Kingdom of"
#Hong Kong, China (SAR)
gender_data[gender_data$Country=='Hong Kong, China (SAR)',"Country"]="Hong Kong, China"
#Iran (Islamic Republic of)
gender_data[gender_data$Country=='Iran (Islamic Republic of)',"Country"]="Iran, Islamic Republic of"
#Korea (Republic of)
gender_data[gender_data$Country=='Korea (Republic of)',"Country"]="Korea, Republic of"
#Micronesia (Federated States of)
gender_data[gender_data$Country=='Micronesia (Federated States of)',"Country"]="Micronesia, Federated States of"
#Moldova (Republic of)
gender_data[gender_data$Country=='Moldova (Republic of)',"Country"]="Moldova, Republic of"
#Tanzania (United Republic of)
gender_data[gender_data$Country=='Tanzania (United Republic of)',"Country"]="Tanzania, United Republic of"
#Venezuela (Bolivarian Republic of)
gender_data[gender_data$Country=='Venezuela (Bolivarian Republic of)',"Country"]="Venezuela, Bolivarian Republic of"
```

```{r}
gender=merge(gender_gap,data_woman,by.x='Country', by.y='Country')
```


##MERGE FINAL

PASO 1: Editamos los paises:
```{r}
#eliminar duplicados 
##Data 1
libertad[libertad$Country=='CÃ´te d\'Ivoire','Country']='Costa de Marfil'
libertad[libertad$Country=='Côte d\'Ivoire','Country']='Costa de Marfil'
libertad[libertad$Country=='China (People\'s Republic of)','Country']='China'
libertad[libertad$Country=='Congo (Democratic Republic of the)','Country']='Democratic Republic of the Congo'
libertad[libertad$Country=='Czech Republic','Country']='Czechia'
libertad[libertad$Country=='Palestinian Authority or West Bank and Gaza Strip','Country']='Palestine'
libertad[libertad$Country=='Slovak Republic','Country']='Slovakia'
##Data 2
sec[sec$Country=='Côte d\'Ivoire','Country']='Costa de Marfil'
sec[sec$Country=='Czech Republic','Country']='Czechia'
sec[sec$Country=='Eswatini (Kingdom of)','Country']='Eswatini'
sec[sec$Country=='Korea (Republic of)','Country']='Korea'
sec[sec$Country=='Palestine, State of','Country']='Palestine'
sec[sec$Country=='Slovak Republic','Country']='Slovakia'
##Data 3
gender[gender$Country=='CÃ´te d\'Ivoire','Country']='Costa de Marfil'
gender[gender$Country=='Congo, Democratic Republic of the','Country']='Democratic Republic of the Congo'
gender[gender$Country=='Czech Republic','Country']='Czechia'
gender[gender$Country=='Eswatini, Kingdom of','Country']='Eswatini'
gender[gender$Country=='Iran, Islamic Republic of','Country']='Iran'
gender[gender$Country=='Korea (Democratic People\'s Rep. of)','Country']='North Korea'
gender[gender$Country=='Korea, Republic of','Country']='Korea'
gender[gender$Country=='Moldova, Republic of','Country']='Moldova'
gender[gender$Country=='Palestine, State of','Country']='Palestine'
gender[gender$Country=='Russian Federation','Country']='Russia'
gender[gender$Country=='Tanzania, United Republic of','Country']='Tanzania'
gender[gender$Country=='Venezuela, Bolivarian Republic of','Country']='Venezuela'
##Data 4
autonomia[autonomia$Country=='Bolivia (Plurinational State of)','Country']='Bolivia'
autonomia[autonomia$Country=='Côte d\'Ivoire','Country']='Costa de Marfil'
autonomia[autonomia$Country=='China (People\'s Republic of)','Country']='China'
autonomia[autonomia$Country=='Congo (Democratic Republic of the)','Country']='Democratic Republic of the Congo'
autonomia[autonomia$Country=='Eswatini (Kingdom of)','Country']='Eswatini'
autonomia[autonomia$Country=='Iran (Islamic Republic of)','Country']='Iran'
autonomia[autonomia$Country=='Korea (Republic of)','Country']='Korea'
autonomia[autonomia$Country=='Moldova (Republic of)','Country']='Moldova'
autonomia[autonomia$Country=='Palestinian Authority or West Bank and Gaza Strip','Country']='Palestine'
autonomia[autonomia$Country=='Russian Federation','Country']='Russia'
autonomia[autonomia$Country=='Slovak Republic','Country']='Slovakia'
autonomia[autonomia$Country=='Tanzania (United Republic of)','Country']='Tanzania'
autonomia[autonomia$Country=='Venezuela (Bolivarian Republic of)','Country']='Venezuela'
```

PASO 2: MERGE
```{r}
#base 1 y 2
baseLyS=merge(libertad,sec,all.x = T, all.y = T)
str(baseLyS)
#base 1-2 y 3
baseLSG=merge(baseLyS,gender,all.x = T, all.y = T)
str(baseLSG)
#base 1-2-3 y 4
baseLSGA=merge(baseLSG,autonomia,all.x = T, all.y = T)
str(baseLSGA)
```

BASE FINAL 
```{r}
Basefinal=baseLSGA
```

PASO 3: PREPARAMOS Y MODIFICAMOS NUESTRA BASE FINAL PARA HACERLA MÁS ENTENDEDIBLE
```{r}
#Uniformizar a 2 digitos el número de decimales a utilizar en nuestra data "Basefinal" 
Basefinal[,c(2:10)]=round(Basefinal[,c(2:10)], digits = 2)

#ordenar las columnas para poner primero la variable dependiente
Basefinal = Basefinal[ , c(1,10,8,9,2,3,4,5,6,7)]
names (Basefinal)
str(Basefinal)
```
Modificando los nombres de las bases
```{r}
#identificar duplicados
Basefinal[!complete.cases(Basefinal),] 
```
```{r}
Basefinal=Basefinal[-c(36,38,60,79,84,96,97,98,100,123,125,157,172,179,180,189,208),]
```

```{r}
#Cambiando row.names
row.names(Basefinal)=Basefinal$Pais 
#verificamos
str(Basefinal)
```



PRODUCTO 1: 

IMPORTAMOS LA DATA BASEFINAL DEL GITHUB
```{r}
library(rio)
basefinal=import('https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv')
data= basefinal
str(data)
```

1. ANALISIS UNIVARIADO DE NUESTAS VARIABLES

PAS0 0: Antes de proceder con el análisis, vamos a recodificar las variables independientes (autonomia y violencia) para poder hacer un mejor analisis.

#Variable Autonomia
```{r}
#Revisamos valores iniciales
table(data$MLAutonomia)
```
```{r}
#Luego, variable debe ser convertida en una variable tipo factor
data$MLAutonomia <- as.factor(data$MLAutonomia)
#Le asignamos etiquetas a los valores
data$MLAutonomia=factor(data$MLAutonomia,
                     levels = levels(data$MLAutonomia),
                     labels = c("Protege totalmente","Protege mucho","Protege","Protege muy poco","No protege"),
                     ordered = T)
#verificamos
str(data$MLAutonomia)
table(data$MLAutonomia)
```

#Variable violencia
```{r}
#Revisamos los valores
table(data$MLViolencia)
```

```{r}
#Empleamos funcion recode
data$MLViolencia<- recode(data$MLViolencia, "0=0 ; 0.25=0 ; 0.5=0.5 ; 0.75=1 ; 1=1")
#Verificamos
table(data$MLViolencia)
```

```{r}
#Luego, variable debe ser convertida en una variable tipo factor
data$Violencia <- as.factor(data$Violencia)
#Le asignamos etiquetas a los valores
data$Violencia=factor(data$Violencia,
                     levels = levels(data$Violencia),
                     labels = c("Protege","Regular","No protege"),
                     ordered = T)#verificamos
                     
str(data$Violencia)
table(data$Violencia)
```

PASO 1: VARIABLE NUMERICA Desigualdad de genero

#Variable dependiente: Indice de Desigualdad de Genero
```{r}
#Solicitamos estadisticos descriptivos
summary(data$DesigualdadGenero)
```

```{r}
library(psych)
describe.by(data$DesigualdadGenero)
str(data)
```

-Analisis grafico de variable
```{r}
#Solicitamos histograma
hist(data$DesigualdadGenero, main = "Desigualdad de genero")
```

PASO 2;:VARIABLE ORDINAL Autonomia reproductiva

```{r}
#Solicitamos estadisticos descriptivos
summary(data$Autonomia)
```


-Analisis grafico de variable
```{r}
#Solicitamos histograma
library(jtools)
barplot(table(data$Autonomia),col="red",
        xlab=NULL,main="Autonomia Reproductiva")
```

PASO 3: VARIABLE ORDINAL Violencia contra la mujer
```{r}
#Solicitamos estadisticos descriptivos
summary(data$Violencia)
```


-Analisis grafico de variable
```{r}
#Solicitamos una grafica de barras
barplot(table(data$Violencia),col="lightgreen",
        xlab=NULL,main="Violencia contra la mujer")
```

PASO 4: VARIABLE NUMERICA VozPolitica

```{r}
#Solicitamos las medidas de tendencia central
library(psych)
library(DescTools)
describeBy(data$VozPolitica)
summary(data$VozPolitica)
```


- Graficos
```{r}
#Solicitamos un histograma
hist(data$VozPolitica, col = "green", main="Voz politica", xlab = "Por parlamento", ylab ="Porcnetaje de mujeres")
```


PASO 5: VARIABLE NUMERICA LibertadMov (libertad de movimiento)
```{r}
#Solicitamos las medidas de tendencia central
describeBy(data$LibertadMov)
summary(data$LibertadMov)
```

- Graficos
```{r}
#Solicitamos un histograma 
hist(data$LibertadMov, col = "lightblue", main="Libertad de movimiento", xlab = "", ylab =NULL)
#Solicitamos un boxplot para ver los outliers
boxplot(data$LibertadMov, col = "red", main="Libertad de movimiento")
```

PASO 6: Analisis descriptivo de la variable "AccesoJ"
```{r}
#Solicitamos el desvrybeBy para el analisis univariado
describeBy(data$AccesoJ, digits=2)
```

- Graficos
```{r}
#Solicitamos un boxplot
boxplot(data$AccesoJ, col = "lightgreen", main="Acceso a Justicia")
#Solicitamos un histograma
hist((data$AccesoJ),col="lightblue",
        xlab="Cantidad de paises",
        ylab="Acceso a justicia",
        main="Acceso a Justicia")
```


PASO 7: Analisis descriptivo de la variable "SecundariaC"
```{r}
#Solicitamos el desvrybeBy para el analisis univariado
describeBy(data$SecundariaC, digits=2)
```

- Graficos
```{r}
#Solicitamos un boxplot
boxplot(data$SecundariaC, col = "lightgreen", main="Secundaria Completa")
#Solicitamos el histograma
hist((data$SecundariaC),col="lightblue",
        xlab="Cantidad de paises",
        ylab="Promedio de mujeres con secundaria completa",
        main="Mujeres con secundaria completa")
```

PASO 8: Analisis descriptivo de la variable "Desempleo"
```{r}
#Solicitamos el desvrybeBy para el analisis univariado
describeBy(data$Desempleo, digits=2)
```

- Graficos
```{r}
#Solicitamos un boxplot
boxplot(data$Desempleo,  col="blue", main="Boxplot de Desempleo")
#Solicitamos el histograma
hist((data$Desempleo), col="blue",
        xlab="Cantidad de paises",
        ylab="Proporcion de mujeres desempleadas",
        main="Mujeres desempleadas")
```

PASO 9: Analisis descriptivo de la variable "CuentaF"
```{r}
#Solicitamos el desvrybeBy para el analisis univariado
describeBy(data$CuentaF, digits=2)
```

```{r}
#Solicitamos un boxplot
boxplot(data$CuentaF, main="Boxplot de Cuenta Financiera ", col="blue")
#Solicitamos el histograma
hist((data$CuentaF), col="blue",
        xlab="Cantidad de paises",
        ylab="Porcentaje de mujeres con banca movil",
        main="Mujeres con banca movil")
```

PASO 10: aplicamos las funciones para todas las vairables a la vez
```{r}
#para varias variables
describeBy(as.matrix(cbind(data[,c(2:10)])), digits = 2)
#summary
summary(data[,c(2:10)])
```


2. ANALISIS BIVARIADO: CORRELACION Y GRÁFICO DE DISPERSION

#PASO 1: ANOVA de un factor entre  "DesigualdadGenero" y "Autonomía"

```{r}
#Aplicamos la prueba ANOVA de un factor. Usamos la nueva variable creada unos pasos atrás.
anovaautonomia <- aov(data$DesigualdadGenero ~ data$Autonomia)
summary(anovaautonomia)
```
RESPUESTA:
                  Pr(>F)    
data$Autonomia   4.26e-09 ***

```{r}
#Prueba de comparaciones múltiples (Tukey)
TukeyHSD(anovaautonomia) 
```
RESPUESTA:
                     p adj
Regular-Protege      0.0001108
No protege-Protege   0.0000000
No protege-Regular   0.9530128

```{r}
#Gráfico de medias con intervalos de confianza (ver superposición)
library(gplots) 
plotmeans(data$DesigualdadGenero ~ Autonomia, data = data,ylab = "Desigualdad de género")
```

#PASO 2: ANOVA de unfactor entre  "DesigualdadGenero"y "Violencia"
```{r}
#Aplicamos la prueba ANOVA de un factor
anovaviolencia <- aov(data$DesigualdadGenero ~ data$Violencia)
summary(anovaviolencia)
```
RESPUESTA:
                  Pr(>F)   
data$Violencia   0.00644 **

```{r}
#Prueba de comparaciones múltiples (Tukey)
TukeyHSD(anovaviolencia)
```
RESPUESTA: 
                    p adj
Regular- Protege    0.0112447
No protege-Protege  0.0113994
No protege-Regular  0.8572113

```{r}
#Gráfico de medias con intervalos de confianza (ver superposición)
plotmeans(data$DesigualdadGenero ~ Violencia, data = data, ylab = "Desigualdad de género")
```


#PASO 3: Correlacion entre  "DesigualdadGenero"y "VozPolitica"
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$VozPolitica, xlab="Voz Politica", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$VozPolitica)
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```

RESPUESTA: cor = -0.3797722  p-value = 6.529e-06

Que tan fuerte es la correlacion? Que sentido tiene? Por que?

#PASO 4: Correlacion entre  "DesigualdadGenero"y "LibertadMov"(libertad de movimiento)
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$LibertadMov, xlab="Libertad de movimiento", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$LibertadMov)
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```
RESPUESTA: cor = -0.4299311  p-value = 2.41e-07

#PASO 5: Correlacion entre  "DesigualdadGenero"y "AccesoJ"(acceso a justicia)
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$AccesoJ, xlab="Acceso a Justicia", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$AccesoJ)
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```
RESPUESTA: cor = -0.1588468   p-value = 0.06888

#PASO 6: Correlacion entre  "DesigualdadGenero"y "SecundariaC"(secundaria completa)
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$SecundariaC, xlab="Secundaria Completa", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$SecundariaC) 
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```
RESPUESTA: cor = -0.7925136   p-value < 2.2e-16

#PASO 7: Correlacion entre  "DesigualdadGenero"y "Desempleo"
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$Desempleo, xlab="Desempleo", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$Desempleo)
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```
RESPUESTA: cor = 0.01774458  p-value = 0.8227

#PASO 8: Correlacion entre  "DesigualdadGenero"y "CuentaF"(Cuenta financiera)
```{r}
#Analisis visual usando un grafico de dispersion
plot(data$DesigualdadGenero, data$CuentaF, xlab="Cuenta financiera", ylab="Desigualdad de Genero")
#Solicitamos la prueba R de Pearson
cor.test(data$DesigualdadGenero, data$CuentaF) 
## H0: Las variables son estadIsticamente independientes
## HA: Las variables son estadIsticamente dependientes
```
RESPUESTA: cor = -0.8300363  p-value < 2.2e-16

#HITO 5:

```{r}
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
data=na.omit(data)
```
PASO 0: ALISTAR BASE DE DATOS

###variable MLAutonomia
```{r}
library(car)
data$MLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
                            levels = levels(data$MLAutonomia),
                            labels = c("5","4","3","2","1"),
                            ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
```

###Variable MLViolencia
```{r}
#Le asignamos etiquetas a los valores
data$MLViolencia <- recode(data$MLViolencia,"0.25=0.75 ; 0.5=0.5 ; 0.75=0.25")
data$MLViolencia <-as.factor(data$MLViolencia)
data$MLViolencia=factor(data$MLViolencia,
                            levels = levels(data$MLViolencia),
                            labels = c("3","2","1"),
                            ordered = T)
data$MLViolencia <-as.numeric(data$MLViolencia)
table(data$MLViolencia)
```

###Normalizamos la variable DesempleoMujM/v
```{r}
library(BBmisc)
data$DesempleoMuj= normalize(data$DesempleoMuj, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 100),)
data$DesempleoMuj=round(data$DesempleoMuj,2)
```

###Creo una base de datos con las variables que usare
```{r}
subdata= data[,c(3,4,5,6,7,8,9,10)]
```

###Preparamos la subdata para la factorizacion
```{r}
subdata$LibertadMov= 100 - subdata$LibertadMov
subdata$ConfianzaSJ= 100 - subdata$ConfianzaSJ
subdata$DesempleoMuj= 100 - subdata$DesempleoMuj
```

###Resumen de data
```{r}
str(subdata)
```
PASO 1: Calculemos matriz de correlación:

```{r}
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
```
2. Explorar correlaciones:
```{r}
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
```

```{r}
#Evaluando significancia:
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix),
          insig = "blank")
```
```{r}
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
```

3. Verificar si datos permiten factorizar:
```{r}
library(psych)
psych::KMO(corMatrix)
```
#VEMOS EL KMO de cada variable
```{r}
KMO(corMatrix)$MSAi
```

4. Verificar si la matriz de correlaciones es adecuada
    - Aqui hay dos pruebas:

 a. Hnula: La matriz de correlacion es una matriz identidad
```{r}
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
```
 b. Hnula: La matriz de correlacion es una matriz singular.
```{r}
library(matrixcalc)
is.singular.matrix(corMatrix)
```

5, Determinar en cuantos factores o variables latentes podríamos redimensionar la subdata:
```{r}
fa.parallel(subdata,fm = 'ML', fa = 'fa')
```

```{r}
#instalar 'parameters' y 'n_factors'
library(parameters)
library(nFactors)
sugerencia=parameters::n_factors(corMatrix)
library(see)
# tenemos:
plot(sugerencia)
```

6. Redimensionar a numero menor de factores

Resultado inicial:
```{r}
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
```

```{r}
print(resfa$loadings)
```

Resultado mejorado:
```{r}
print(resfa$loadings,cutoff = 0.5)
```
Cuando logramos que cada variable se vaya a un factor, tenemos una estructura simple.

Resultado visual:
```{r}
fa.diagram(resfa)
```

7. Evaluando Resultado obtenido:
```{r}
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
```
```{r}
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
```
```{r}
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
```
```{r}
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
```
```{r}
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
```

8.Posibles valores proyectados:

Creamos un data set
```{r}
factoriales=as.data.frame(resfa$scores)
head(factoriales)
```

o incluirlos en nuestro subset original

```{r}
subdata$factor1<- factoriales$MR1
subdata$factor2<- factoriales$MR2
subdata$factor3<- factoriales$MR3
summary(factoriales)
```

```{r}
subdata=cbind(data[,c(1,2)],subdata)
```

```{r}
subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero 
```

RECORDANDO:

```{r}
library(fpc)
library(cluster)
library(dbscan)
# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]
g.dist.cmd = daisy(subdata[,c(11:13)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
abline(h= 0.62,col='red')
```
Para tener una idea de cada quien:
```{r}
res.DB=fpc::dbscan(g.dist.cmd, eps=0.62, MinPts=3,method = 'dist')
subdata$clustDB=as.factor(res.DB$cluster)
aggregate(cbind(factor1, factor2,factor3) # dependientes
         ~ clustDB, # nivel
        data = subdata,    # data
          max)            # operacion
```

Finalmente, veamos relaciones:
```{r}
library(BBmisc)
subdata$factor1=normalize(subdata$factor1, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
subdata$factor2=normalize(subdata$factor2, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
subdata$factor3=normalize(subdata$factor3, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
```

You can see them all here:
```{r}
plot(subdata$factor1,subdata$DesigualdadGenero)
plot(subdata$factor2,subdata$DesigualdadGenero)
plot(subdata$factor3,subdata$DesigualdadGenero)
```


#REGRESIONES
```{r}
hipotesis = formula(DesigualdadGenero ~ factor1)
regresion=lm(hipotesis,data=subdata)
summary(regresion)
```
```{r}
hipotesis1 = formula(DesigualdadGenero ~ factor2)
regresion1=lm(hipotesis1,data=subdata)
summary(regresion1)
```

```{r}
hipotesis2 = formula(DesigualdadGenero ~ factor3)
regresion2=lm(hipotesis2,data=subdata)
summary(regresion2)
```

```{r}
hipotesis3 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3)
regresion3=lm(hipotesis3,data=subdata[,-c(1)])
summary(regresion3)
```

#DIAGNOSTICO DE LA REGRESION

  - Para que se considere que el modelo de regresión elegido es el adecuado, debemos verificar algunos 
    requisitos a posteriori:

1. Linealidad:
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(regresion3, 1)
```
2. Homocedasticidad

  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(regresion3, 3)
```

También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# null: modelo homocedastico
bptest(regresion3)
```

  - La probabilidad de homocedasticidad es alta (p-value menor a 0.08), de el modelo muestra homocedasticidad.

3. Normalidad de los residuos

Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(regresion3, 2)
```

Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(regresion3$residuals)
```

4. No multicolinelidad

  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(regresion3) # > 5 es problematico
```



Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(regresion3$residuals)
```

4. No multicolinelidad

  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(regresion3) # > 5 es problematico
```

5. Valores influyentes
```{r}
plot(regresion3,5)
```
RESPUESTA: Se concluye que si hay casos influyentes que son el 29,160,205

EL MODELO NOS PERMITE PREDECIR, ESTA ECUACION TIENE COEFICIENTES. SIN EMBARGO, PUEDEN HABER ALGUNOS CASOS QUE INFLUYEN EN EL MODELO QUE HAS COSNTRUIDO PORQUE SON DISTANTES. En este caso el caso 29, dista mucho de los demas casos y altera el calculo de nuestro modelo. 

```{r}
checkregresion3=as.data.frame(influence.measures(regresion3)$is.inf)
head(checkregresion3)
```

#HITO 6:
```{r}
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
data=na.omit(data)
```
###variable MLAutonomia
```{r}
library(car)
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
                            levels = levels(data$MLAutonomia),
                            labels = c("1","2","3","4","5"),
                            ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
```

###Variable MLViolencia
```{r}
#Le asignamos etiquetas a los valores
data$MLViolencia <-as.factor(data$MLViolencia)
data$MLViolencia=factor(data$MLViolencia,
                            levels = levels(data$MLViolencia),
                            labels = c("1","2","3"),
                            ordered = T)
data$MLViolencia <-as.numeric(data$MLViolencia)
table(data$MLViolencia)
```

PASO 0: ALISTAR BASE DE DATOS

###Creo una base de datos con las variables que usare
```{r}
names(data)[7]='DesconfianzaSJ'
subdata= data[,c(3,4,5,6,7,8,10)]
```

###Preparamos la subdata para la factorizacion
```{r}
subdata$SecundariaC= 100 - subdata$SecundariaC
subdata$CuentaF= 100 - subdata$CuentaF
subdata$VozPolitica= 100 - subdata$VozPolitica
```

###Resumen de data
```{r}
str(subdata)
```

PASO 1: Calculemos matriz de correlación:

```{r}
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
```
2. Explorar correlaciones:
```{r}
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
```

```{r}
#Evaluando significancia:
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix),
          insig = "blank")
```
```{r}
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
```

3. Verificar si datos permiten factorizar:
```{r}
library(psych)
psych::KMO(corMatrix)
```
4. Verificar si la matriz de correlaciones es adecuada
    - Aqui hay dos pruebas:

 a. Hnula: La matriz de correlacion es una matriz identidad
```{r}
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
```
 b. Hnula: La matriz de correlacion es una matriz singular.
```{r}
library(matrixcalc)
is.singular.matrix(corMatrix)
```

5, Determinar en cuantos factores o variables latentes podríamos redimensionar la subdata:
```{r}
fa.parallel(subdata,fm = 'ML', fa = 'fa')
```


6. Redimensionar a numero menor de factores

Resultado inicial:
```{r}
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
```

```{r}
print(resfa$loadings)
```
RESPUESTA: 57.4% de las caracteristicas de las variables,es un problema porque se pierde bastante información.No se utiliza el EFA.

Resultado mejorado:
```{r}
print(resfa$loadings,cutoff = 0.5)
```
Cuando logramos que cada variable se vaya a un factor, tenemos una estructura simple.

Resultado visual:
```{r}
fa.diagram(resfa)
```
CONCLUSION: los tres factores obtenidos en el análisis factorial no corresponde a las variables latentes propuestas segun la revision de literatura.

7. Evaluando Resultado obtenido:
```{r}
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
```
```{r}
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
```
```{r}
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
```
```{r}
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
```
```{r}
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
```

8.Posibles valores proyectados:

Creamos un data set
```{r}
factoriales=as.data.frame(resfa$scores)
head(factoriales)
```

o incluirlos en nuestro subset original

```{r}
subdata$factor1<- factoriales$MR1
subdata$factor2<- factoriales$MR2
subdata$factor3<- factoriales$MR3
summary(factoriales)
```

9. REINCORPORAMOS AL SUBDATA LAS VARIABLES QUE SE NECESITAN PARA LA REGRESION (PAIS,DESIGUALDADDEGENERO Y
   DESEMPELO MUJ)
```{r}
subdata=cbind(data[,c(1,2,9)],subdata)
```

10. NORMALIZAMOS LOS FACTORES Y NUESTRO INDICE DE DESIGUALDAD DE GENERO
```{r}
library(BBmisc)
subdata$DesigualdadGenero=normalize(subdata$DesigualdadGenero, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
subdata$factor1=normalize(subdata$factor1, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
subdata$factor2=normalize(subdata$factor2, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
subdata$factor3=normalize(subdata$factor3, 
                      method = "range", 
                      margin=2, # by column
                      range = c(0, 100))
```
añadir correlaciones con cada factor independiente
```{r}
f1=formula(~DesigualdadGenero + factor1) #v. dependiente y v. independiente
# camino parametrico
pearson1=cor.test(f1,data=subdata)
pearson1
```
```{r}
f2=formula(~DesigualdadGenero + factor2) #v. dependiente y v. independiente
# camino parametrico
pearson2=cor.test(f2,data=subdata)
pearson2
```
```{r}
f3=formula(~DesigualdadGenero + factor3) #v. dependiente y v. independiente
# camino parametrico
pearson3=cor.test(f3,data=subdata)
pearson3
```

11. GRAIFCAS DE LAS CORRELACIONES
```{r}
plot(subdata$factor1,subdata$DesigualdadGenero)
plot(subdata$factor2,subdata$DesigualdadGenero)
plot(subdata$factor3,subdata$DesigualdadGenero)
```

#REGRESIONES
```{r}
hipotesis1= formula(DesigualdadGenero ~ factor1)
regresion1=lm(hipotesis1,data=subdata)
summary(regresion1)
```
```{r}
hipotesis2 = formula(DesigualdadGenero ~ factor3)
regresion2=lm(hipotesis2,data=subdata)
summary(regresion2)
```

```{r}
hipotesis3 = formula(DesigualdadGenero ~ factor1 + factor3)
regresion3=lm(hipotesis3,data=subdata)
summary(regresion3)
```

```{r}
hipotesis4 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3)
regresion4=lm(hipotesis4,data=subdata[,-c(1)])
summary(regresion4)
```
```{r}
library(stargazer)
stargazer(regresion3, regresion4, type = "text")
```

CONCLUSION: nos convendria

#agregamos desmepleo como variable CONTROL (PONER EN ANEXO)
```{r}
hipotesis5 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3+ DesempleoMuj)
regresion5=lm(hipotesis5,data=subdata[,-c(1)])
summary(regresion5)
```
#DIAGNOSTICO DE LA REGRESION CON LOS FACTORES
  - Para que se considere que el modelo de regresión elegido es el adecuado, debemos verificar algunos 
    requisitos a posteriori:
1. Linealidad:
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(regresion4, 1)
```
2. Homocedasticidad

  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(regresion4, 3)
```
También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# null: modelo homocedastico
bptest(regresion4)
```
3. Normalidad de los residuos
Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(regresion3, 4)
```
Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(regresion4$residuals)
```
4. No multicolinelidad
- Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(regresion4) # > 5 es problematico
```
5. Valores influyentes
```{r}
plot(regresion4,5)
```
RESPUESTA: Se concluye que si hay casos influyentes que son Namibia, Bolivia y South Africa
```{r}
checkregresion4=as.data.frame(influence.measures(regresion4)$is.inf)
head(checkregresion4)
checkregresion4[checkregresion4$cook.d|checkregresion4$hat,]
#no todo valor outlier es influyente pero si todo valor influyente es outlier
```

12. AL REALIZAR EL EFA NOS DAMOS CUENTA QUE NO ES VIABLE POR LO TANTO REALZIAMOS LAS REGRESIONES SOLO CON LAS VARIABLES OBSERVABLES Y YA NO CON FACTORES

A. Primero analziamos las correlaicones entre las variables observables y el indice
```{r}
library(polycor)
correlaciones=polycor::hetcor(subdata[,-c(1,11,12,13)])$correlations
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(correlaciones)
```
```{r}
correlaciones
```

#REGRESION CON CADA VARIABLE
```{r}
mod1=lm(subdata$DesigualdadGenero ~ subdata$MLAutonomia)
summary(mod1)
```
```{r}
mod2=lm(subdata$DesigualdadGenero ~ subdata$MLViolencia)
summary(mod2)
```
```{r}
mod3=lm(subdata$DesigualdadGenero ~ subdata$VozPolitica)
summary(mod3)
```
```{r}
mod4=lm(subdata$DesigualdadGenero ~ subdata$LibertadMov)
summary(mod4)
```
```{r}
mod5=lm(subdata$DesigualdadGenero ~ subdata$Desconfianza)
summary(mod5)
```
```{r}
mod6=lm(subdata$DesigualdadGenero ~ subdata$DesempleoMuj)
summary(mod6)
```
```{r}
mod7=lm(subdata$DesigualdadGenero ~ subdata$SecundariaC)
summary(mod7)
```
```{r}
mod8=lm(subdata$DesigualdadGenero ~ subdata$CuentaF)
summary(mod8)
```


13. MODELOS FINALES DE REGRESION
```{r}
MF0=lm(DesigualdadGenero ~ .,data=subdata[,-c(1)])
summary(MF0)
```

#MODELO 1
```{r}
MF1=lm(subdata$DesigualdadGenero ~ subdata$MLAutonomia +subdata$LibertadMov + subdata$SecundariaC + subdata$CuentaF)
anova(MF1)
library(stargazer)
stargazer(MF1, type = "text")
```

##DIAGNOSTICO DEL MODELO 2
A.LINEALIDAD
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(MF1, 1)
```
B. Homocedasticidad
   Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(MF1, 3)
```
También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# Hnull: modelo homocedastico
bptest(MF1)
```
C. Normalidad de los residuos
- Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(MF1, 2)
```
Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(MF1$residuals)
```

D.No multicolinelidad
  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(MF1) # > 5 es problematico
```

5. Valores influyentes
```{r}
plot(MF1,5)
```
```{r}
checkMF1=as.data.frame(influence.measures(MF1)$is.inf)
head(checkMF1)
checkMF1[checkMF1$cook.d|checkMF1$hat,] 
```



#MODELO 2
```{r}
MF2=lm(subdata$DesigualdadGenero ~ subdata$MLAutonomia +subdata$SecundariaC + subdata$CuentaF+ subdata$VozPolitica)
anova(MF1)
stargazer(MF2, type = "text")
```
##DIAGNOSTICO DEL MODELO 2
A.LINEALIDAD
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(MF2, 1)
```
B. Homocedasticidad
   - A MAYORES valores pronosticados el erro es mayor. entonces la varianza no es igual, ES UN MODELO HETEROCES
  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(MF2, 3)
```
También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# Hnull: modelo homocedastico
bptest(MF2)
```

  - La probabilidad de homocedasticidad es alta, de el modelo muestra homocedasticidad.

C. Normalidad de los residuos

Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(MF2, 2)
```
###como interpretar el QQPLOT

Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(MF2$residuals)
```
- SI HAY UNS DISTRIBUCION NORMAL

D.No multicolinelidad
  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(MF2) # > 5 es problematico
```

5. Valores influyentes
```{r}
plot(MF2,5)
```
RESPUESTA: segun el grafico hay un indicio que si hay tres casos influyentes pero se verificará tomando en cuenta la distancia cook y el hat.

```{r}
checkMF2=as.data.frame(influence.measures(MF2)$is.inf)
head(checkMF2)
checkMF2[checkMF2$cook.d|checkMF2$hat,] 
```
RESPUESTA: no hay valores influyentes


#MODELO 3
```{r}
MF3=lm(subdata$DesigualdadGenero ~ subdata$MLAutonomia +subdata$CuentaF + subdata$SecundariaC)
anova(MF3)
stargazer(MF3, type = "text")
```

##DIAGNOSTICO DEL MODELO 3
A.LINEALIDAD
   - Se asume relación lineal entre Y y X:
```{r}
# linea roja debe tender a horizontal
plot(MF3, 1)
```
B. Homocedasticidad
   - A MAYORES valores pronosticados el erro es mayor. entonces la varianza no es igual, ES UN MODELO HETEROCES
  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
```{r}
# linea roja debe tender a horizontal
plot(MF3, 3)
```
También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
# Hnull: modelo homocedastico
bptest(MF3)
```

  - La probabilidad de homocedasticidad es alta, de el modelo muestra homocedasticidad.

C. Normalidad de los residuos

Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(MF3, 2)
```
###como interpretar el QQPLOT

Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(MF3$residuals)
```
- SI HAY UNS DISTRIBUCION NORMAL

D.No multicolinelidad
  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(MF3) # > 5 es problematico
```

5. Valores influyentes
```{r}
plot(MF3,5)
```
RESPUESTA: segun el grafico hay un indicio que si hay tres casos influyentes pero se verificará tomando en cuenta la distancia cook y el hat.

```{r}
checkMF3=as.data.frame(influence.measures(MF3)$is.inf)
head(checkMF3)
checkMF3[checkMF3$cook.d|checkMF3$hat,] 
```
RESPUESTA: no hay valores influyentes


14. COMPARACION DE MODELOS
```{r}
stargazer(MF1,MF2,MF3, type = "text") #TRES putnso nos dan un alto valor de significancia, el primero es el estimado o cieficiente, el entre parentesis es el error residual.
```



