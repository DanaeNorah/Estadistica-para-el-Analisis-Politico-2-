library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
indice=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/HDI_2018.xlsx')
subdata=indice
LIMPIEZA
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
indice=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/HDI_2018.xlsx')
subdata=indice
#LIMPIEZA
#elimino fila
subdata=subdata[-c(1:4,6,7),]
#cambio nombes
names(subdata)=subdata[c(1),]
#elimino fila
subdata=subdata[-c(1),]
#elimino fila
subdata=subdata[,-c(1,4,6,8,10,11,12,13,14,15)]
#eliminar espacios
subdata$Country=trimws(subdata$Country,whitespace = "[\\h\\v]")
#numerica
str(subdata)
subdata[,c(2:5)]=lapply(subdata[,c(2:5)], as.numeric)
str(subdata)
subdata=na.omit(subdata)
subdata[!duplicated(subdata),]
##Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$Country
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:5)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:5)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
View(subdata)
View(subdata)
View(indice)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:5)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,4,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 4,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 4,hc_func='diana') #Indicamos 3 por el resultado anterior
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
subdata$p
View(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(3:5)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(3:5)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(3:5)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
View(indice)
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
indice=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/HDI_2018.xlsx')
subdata=indice
#LIMPIEZA
#elimino fila
subdata=subdata[-c(1:4,6,7),]
#cambio nombes
names(subdata)=subdata[c(1),]
#elimino fila
subdata=subdata[-c(1),]
#elimino fila
subdata=subdata[,-c(1,4,6,8,10,11,12,14,15)]
#eliminar espacios
subdata$Country=trimws(subdata$Country,whitespace = "[\\h\\v]")
#numerica
str(subdata)
subdata[,c(2:6)]=lapply(subdata[,c(2:6)], as.numeric)
str(subdata)
subdata=na.omit(subdata)
subdata[!duplicated(subdata),]
##Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$Country
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:6)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:6)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:6)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,4,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 4,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 4,hc_func='diana') #Indicamos 3 por el resultado anterior
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
subdata$p
View(subdata)
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
indice=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/HDI_2018.xlsx')
subdata=indice
#LIMPIEZA
#elimino fila
subdata=subdata[-c(1:4,6,7),]
#cambio nombes
names(subdata)=subdata[c(1),]
#elimino fila
subdata=subdata[-c(1),]
#elimino fila
subdata=subdata[,-c(1,4,6,8,10,11,12,14,15)]
#eliminar espacios
subdata$Country=trimws(subdata$Country,whitespace = "[\\h\\v]")
#numerica
str(subdata)
subdata[,c(2:6)]=lapply(subdata[,c(2:6)], as.numeric)
str(subdata)
subdata=na.omit(subdata)
subdata[!duplicated(subdata),]
##Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$Country
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:6)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:6)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:6)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,4,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 4,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 4,hc_func='diana') #Indicamos 3 por el resultado anterior
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
subdata$p
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
seguridad=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/seguridadUSA.xlsx')
subdata=seguridad
str(subdata)
#a. Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$estado
# alternativa a complete.cases:
subdata=na.omit(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:4)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:4)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:4)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
subdata$aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
seguridad=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/seguridadUSA.xlsx')
subdata=seguridad
str(subdata)
#a. Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$estado
# alternativa a complete.cases:
subdata=na.omit(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:4)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:4)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:4)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
subdata$aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
seguridad=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/seguridadUSA.xlsx')
subdata=seguridad
str(subdata)
#a. Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$estado
# alternativa a complete.cases:
subdata=na.omit(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:4)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:4)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
seguridad=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/seguridadUSA.xlsx')
subdata=seguridad
str(subdata)
#a. Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$estado
# alternativa a complete.cases:
subdata=na.omit(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:4)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:4)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:4)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 3,hc_func='diana') #Indicamos 3 por el resultado anterior
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
subdata$p
# Revisamos cómo se ve ese elemento widths
head(particion$silinfo$widths)
# Creamos un data.frame que sea equivalente a ese elemento
widths.particion=data.frame(particion$silinfo$widths)
# Creamos un vector que sea el nombre de la región. Lo jalamos del nombre de la fila./ para que salga el nombre en el grafico
widths.particion$Id=row.names(widths.particion)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0./ que muestre cual es el negativos
malos.widths.particion= widths.particion [widths.particion$sil_width> 0,'Id']
malos.widths.particion
#cantidad de casos
length(malos.widths.particion)
# Revisamos cómo se ve ese elemento widths
head(aglomerativo$silinfo$widths)
# Creamos un data.frame que sea equivalente a ese elemento
widths.aglomerativo=data.frame(aglomerativo$silinfo$widths)
# Creamos un vector que sea el nombre de la región. Lo jalamos del nombre de la fila.
widths.aglomerativo$Id=row.names(widths.aglomerativo)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0.
malos.widths.aglomerativo=widths.aglomerativo[widths.aglomerativo$sil_width<0,'Id']
malos.widths.aglomerativo
#cantidad de casos
length(malos.widths.aglomerativo)
# Revisamos cómo se ve ese elemento widths
head(divisivo$silinfo$widths)
# Creamos un data.frame que sea equivalente a ese elemento
widths.divisivo=data.frame(divisivo$silinfo$widths)
# Creamos un vector que sea el nombre de la región. Lo jalamos del nombre de la fila.
widths.divisivo$Id=row.names(widths.divisivo)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0.
malos.widths.divisivo=widths.divisivo[widths.divisivo$sil_width<0,'Id']
malos.widths.divisivo
#cantidad de casos
length(malos.widths.divisivo)
#Generamos el escalamiento usanto las distancias calculadas. Es decir el g.dist
proyeccion = cmdscale(g.dist, k=2,add = T) #k es el número de dimensiones solicitadas
#Creamos una nueva columna en nuestra data que sea la primera dimensión
subdata$dim1 <- proyeccion$points[,1]
#Creamos una nueva columna en nuestra data que sea la segunda dimensión
subdata$dim2 <- proyeccion$points[,2]
#GRAFICANDO (REPASAR GGPLOT!!)
base= ggplot(subdata,aes(x=dim1, y=dim2,label=row.names(subdata)))
base + geom_text(size=2)
#Coloreando el mapa
#Creemos primero las columnas
subdata$c.particion=as.factor(particion$clustering)#particion es la lista, y el clustering es la lista de los cluster
subdata$c.aglomerativo=as.factor(aglomerativo$cluster)
subdata$c.divisivo=as.factor(divisivo$cluster)
##el factor es para despues graficar, si esta en numero no sale
##dyscrebyby o aggreggate las variables deben ser factores
#Estimando límites
min(subdata[,c('dim1','dim2')]); max(subdata[,c('dim1','dim2')])
#GRAFICAS PARA PAM AGNES Y DIANA
limites=c(-0.64,0.42) #Estos límites deben incluir los números obtenidos con el comando anterior
base= ggplot(subdata,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
base + geom_point(size=2, aes(color=c.particion))  + labs(title = "PARTICIONANTE")
base + geom_point(size=2, aes(color=c.aglomerativo)) + labs(title = "AGLOMERATIVO")
base + geom_point(size=2, aes(color=c.divisivo)) + labs(title = "DIVISIVO")
#Calculando nuevas distancias (euclideandas) utilizando las dimensiones creadas anteriormente.
g.dist.cmd = daisy(subdata[,c('dim1','dim2')], metric = 'euclidean')
#CALCULANDO EL EPSilon. Tenemos que ver en qué parte la curva eleva su ángulo drásticamente.
library(dbscan)
kNNdistplot(g.dist.cmd, k=4) # Consideramos 4 como el número mínimo de vecinos (puntos)
abline(h=0.17, lty=2)
##ver la gráfica en donde se eleva la curva
# Generamos la agrupación de densidada, es decir, una lista con información así como las otras estrategias.
install.packages("fpc")
View(widths.aglomerativo)
View(widths.particion)
View(widths.divisivo)
View(particion)
View(widths.particion)
malos.widths.particion
#cantidad de casos
length(malos.widths.particion)
malos.widths.particion
# Creamos un data.frame que sea equivalente a ese elemento
widths.particion=data.frame(particion$silinfo$widths)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0./ que muestre cual es el negativos
malos.widths.particion= widths.particion [widths.particion$sil_width> 0,'Id']
malos.widths.particion
# Revisamos cómo se ve ese elemento widths
head(particion$silinfo$widths)
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0./ que muestre cual es el negativos
malos.widths.particion= widths.particion [widths.particion$sil_width> 0,'Id']
# Creamos un objeto que sea los nombres de aquellos casos cuyos widths sean menor a 0./ que muestre cual es el negativos
malos.widths.particion= widths.particion [widths.particion$sil_width> 0,'Id']
malos.widths.particion
#cantidad de casos
length(malos.widths.particion)
View(widths.particion)
View(particion)
