

```{r}
link="https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav"

data=import(link)

```
- La via formal, tendriamos que ver la normalidad multivariada y la correlacion

```{r}
str(data)
```
- volver a un factor y despues codificar en ejemplo sexo

1. REGRESION SIMPLE
```{r}
modelo1=lm(salario_actual~salario_inicial,data=data)
summary(modelo1)
```
- primero p value es menor a 0.05, entonces si es un modelo valido
- es un modelo que ayuda a predicir una cantidad significativa de nuestra varible dependiente. un 77%
- despues, ver si aportao no la vairable independiente a aprtir del p value. se concluye que si aporta.
```{r}
modelo1$coefficients
```

- la ecuación lineal de la RECTA:
```{r}
#salario_actual=1928.20576 +(1.90945*salario_inicial)

salario_actual = 1928.20576 +(1.90945*10000)
salario_actual
```


2. REGRESION LINEAL MULTIPLE
```{r}
modelo2=lm(salario_actual~ salario_inicial+antiguedad,data=data)
summary(modelo2)
```
INTERPRETAMOS:
1. El modelo 2 si es valido porque su p value del ANOVA es significativo al ser menor a 0.05

2. El modelo 2 explica un 78.4%.al ver el R cuadrado ajustado, si explica mas que el anterio, sube 1%

3. Abas variables independientes aportan al modelo, porque su p-value es menor a 0.05.

4. la regresion lineal seria:
```{r}
modelo2$coefficients
```

```{r}
#salario_actual= -12120.8133 + (1.9138*salario_inicial) + (172.2974*antiguedad)

salario_actual= -12120.8133 + (1.9138*10000) + (172.2974*70)
salario_actual
```


TERCER MODELO
```{r}
modelo3=lm(salario_actual~ salario_inicial+antiguedad+factor(sexo),data=data)
summary(modelo3)
```
```{r}
modelo3$coefficients
```

Formula de regresion lineal multiple
```{r}
#salario_actual3= -11675.916484 +(1.862779*salario_inicia)+ (165.718578*aniguedad) + (1758.013925*factor(sexo)1) 

#si es mujer=0
#si es varon=1
```

En caso sea mujer:
```{r}
salario_actual= -11675.916484 +(1.862779*salario_inicia)+ (165.718578*aniguedad) + (1758.013925*0) 
```

En caso sea hombre: 
```{r}
#salario_actual= -11675.916484 +(1.862779*salario_inicia)+ (165.718578*aniguedad) + (1758.013925*1) 

salario_actual= -11675.916484 +(1.862779*10000)+ (165.718578*2) + (1758.013925*1) 
salario_actual
```

Por cada unidad de salario incial que aumenta estando todo lo demas constante, el salario actual aumenta en 11675.916484


###para el trbaajo veo cuales tienen mayor relacion, despues veo la prueba t o la anova(cuando tengo de dos variables a mas)

###lo agregas como variable control si es significativo porque en la categoria te dice que es indispensable. por eejmplo, seria el desempleo

COMPARACION DE LOS MODELOS

```{r}
anova(modelo1,modelo2,modelo3)
```


```{r}
library(stargazer)
stargazer(modelo1,modelo2,modelo3,type ="text", no.space = F, digits =3)
```
¿Que modelo explica mejor?
- el modelo 3 explica mejor, porque el R cuadrado ajustado es mayor en el modelo 3 (78.6%).Los modelos no difieren porque hay una mejora al aumentar mas variables.

NOTA: me quedo con el modelo que tiene menos variables por el principio de parsimonia, esto solo si tiene el mismo r cuadrado ajustado


DIAGNOSTICO DE LA REGRESION

  - Para que se considere que el modelo de regresión elegido es el adecuado, debemos verificar algunos requisitos a posteriori:

1. Linealidad:

   - Se asume relación lineal entre Y y Xs:
```{r}
# linea roja debe tender a horizontal
plot(modelo3, 1)
```
RESPUESTA: Evaluando este grafico observo que la linea roja dista mucho de la linea puntada, por ello, no esta pegada y concluyo que NO hay linealidad. 


2. Homocedasticidad
  - Se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación (MATH^):
  - cuando la vairanza de los errores es cosntante
```{r}
# linea roja debe tender a horizontal
plot(modelo3, 3)
```
RESPUESTA: debe haber una linea horizontal para afirmar que hay homocedasticidad.Concluyo que no es homocedastico, sino heterocedastico y es un problema.

#También podemos utilizar el test de Breusch-Pagan:
```{r}
library(lmtest)
bptest(modelo3)
```
- Hipotesis nula: modelo homocedastico

RESPUESTA: La probabilidad de homocedasticidad es muy baja (p-value menor a 0.05), rechazo la hipotesis nula, es decir, que el modelo muestre homocedasticidad o sea mocedastico

RESPUESTA: El escenario ideal es que sea HOMOCEDÁSTICO. La Ho es que el modelo es homocedástico. Si el p-valor sale menor a 0.05 rechazo la hipótesis nula y concluyo que es heterocedástico. Si sale mayor entonces concluyo que es homocedástico.

NOTA: el mejor caso es que el p valuo no sea menor a 0.05, para comprobar homocedasticidad es que sea mayor a 0.05


3. Normalidad de los residuos

Los residuos, la diferencia entre MATH y MATH^, debe distribuirse de manera normal:
```{r}
# puntos cerca a la diagonal
plot(modelo3, 2)
```
RESPUESTA: en el grafico vemos si los puntos estan sobre la diagonal, al no estar sobre la diagonal NO ES NORMAL.

Podemos aplicar el test de Shapiro a los residuos:
```{r}
shapiro.test(modelo3$residuals)
#hipotesis nula=distribucion normal de los residuos
```
RESPUESTA: al ser menor a 0.05 los residos no cuentan con distibucion normal. Entonces no hay normalidad de los residuos 


4. No multicolinelidad
  - Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad, lo cual no es deseable:
```{r}
library(DescTools)
VIF(modelo3) # > 5 es problematico
```
RESPUESTA: no hay MULTICOLINEALIDAD porque los valores son menor a 5. Esta es una situación positiva porque lo deseable es que no haya muticolinealidad.


5. Valores influyentes
```{r}
plot(modelo3,5)
```
RESPUESTA: Se concluye que si hay casos influyentes que son el 29,160,205

EL MODELO NOS PERMITE PREDECIR, ESTA ECUACION TIENE COEFICIENTES. SIN EMBARGO, PUEDEN HABER ALGUNOS CASOS QUE INFLUYEN EN EL MODELO QUE HAS COSNTRUIDO PORQUE SON DISTANTES. En este caso el caso 29, dista mucho de los demas casos y altera el calculo de nuestro modelo. 

```{r}
checkmodelo3=as.data.frame(influence.measures(modelo3)$is.inf)
head(chekmodelo3)
```
- Entonces solo hay solo 6 casos influyentes


