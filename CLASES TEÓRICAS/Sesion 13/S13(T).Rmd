
SESION 13 - INTRODUCCIÓN A LA REGRESIÓN LOGÍSTICA MULTIVARIADA


La data de este material está basada en el trabajo de Cowles y Davis.

Esta investigación desea saber si el ofrecerse como voluntario está relaciondo con el sexo de la persona, su nivel de neuroticismo y su nivel de extraversión.

Parte 1. Preparación de datos

#1. Colección
 - Traigamos la data
```{r}
library(rio)
link="https://docs.google.com/spreadsheets/d/e/2PACX-1vTnBAuw8v3PgGMivOBI9tFfGjVrZsVnteUF2y44HjZneYoajlrb9k61kWN300Q-n1q04iy8_nsB68n_/pub?gid=1431542138&single=true&output=csv"
vol=read.csv(link, stringsAsFactors = F)
```
- Verificamos qué tipo de datos tenemos:
```{r}
str(vol)
```

#2. Pre procesamiento
 - Hay dos columnas que deben ser convertidas a categóricas.
```{r}
vol[,c(3,4)]=lapply(vol[,c(3,4)],as.factor)
str(vol)
```

#3. Exploración
 - Una vez formateada, exploremos la data estadisticamente
```{r}
summary(vol)
```
IMPORTANTE: * Las categóricas siempre se almacenan internamente como números, y éstos se asignarán por defecto en orden alfabético. De ahi que el primer nivel de cada categórica se conoce como la categoría de referencia. * Hay funciones que requieren usar los factores como números, en ese sentido, asegurate que el orden de las categóricas sea el correcto: que el evento de interés sea el mayor valor (en esta caso voluntario):

## original
```{r}
table(vol$volunteer)
```
## como numero
```{r}
table(as.numeric(vol$volunteer))
```


Parte 2. Análisis bivariado

# 1. Usando la tabla de contingencia
   - Queremos saber si ser mujer está relacionado con ser voluntario en proyectos de investigación. Al
     ser ambas categóricas, y ser la hipótesis asimétrica o direccional, preparemos una tabla de
     contingencia que muestre ello:
```{r}
dep=vol$volunteer # a la fila
ind=vol$sex # a la columna

volsexTable=table(dep,ind,dnn = c('volunteer','sex'))
```
## suma por columna
```{r}
addmargins(volsexTable,margin = 1)
```

Saber si ser mujer está relacionado con ser voluntario implica saber dos cosas más:

- Si elijo una mujer al azar, qué probabilidad se tiene que ésta sea voluntaria.
- Cómo comparo el “voluntarismo” de la mujer con la del hombre.


#2. Probabilidades y ODDS

A. Caso de la mujer:
- La probabilidad que una mujer sea voluntaria es la división del ser voluntaria entre el total de mujeres:
```{r}
probMV=volsexTable[2,1]/sum(volsexTable[,1])
probMV
```

-La probabilidad es un valor que va de 0 a 1. Recuperemos lo valores de la tabla de contingencia:
```{r}
library(MASS)
fractions(probMV)
```

-Representemos el odds que sea voluntaria, la división entre ser o no ser voluntaria:
```{r}
volsexTable[2,1]/volsexTable[1,1]
```

Que se origina de:
```{r}
fractions(volsexTable[2,1]/volsexTable[1,1])

```

El odds suele representarse además como la razón entre dos probabilidades: la probabilidad que ocurra un evento dividido por la probabilidad que NO ocurra ese evento:
```{r}
OddsMV=probMV/(1-probMV)
OddsMV
```

B. Caso del hombre:

Probabilidad que una hombre sea voluntario
```{r}
probHV=volsexTable[2,2]/sum(volsexTable[,2])
probHV
```
O…
```{r}
fractions(probHV)
```

El odds que el hombre sea voluntario:
```{r}
OddsHV=probHV/(1-probHV)
OddsHV
```
O…
```{r}
fractions(OddsHV)
```

C. Comparando Mujer y Hombre:
  - Hasta aquí ya sabemos cuál odds ha salido mayor. Eso es información clara. Para precisar esa
    información, podemos dividir los odds, lo que nos da el odds ratio, que en este caso nos dirá qué
    diferencia produce el sexo en el voluntariado:
```{r}
(OR_MH=OddsMV/OddsHV)
```

RESPUESTA: Con ese valor, ya sabemos que el odds de ser mujer es 0.28 por encima del odds del hombre. El odds ratio (OR) puede ir de 0 a infinito. Un OR de 1 implica que no hay diferencias.

Osea, el OR para este caso es el esfuerzo que le falta al hombre para llegar al nivel de la mujer:
```{r}
OddsHV*OR_MH
```

Si quieres verlo como fracción:
```{r}
fractions(OddsMV/OddsHV)
```

- Esto informa que la cantidad de mujeres que encontrarias de voluntarias ante una cantidad de hombres voluntarios.

D. Porcentajes y gráficas

- Veamos la tabla de contingencia con los porcentajes por columna:
```{r}
prop.table(volsexTable,margin = 2)
```

Grafiquemoslo:
```{r}
mosaicplot( t(volsexTable),col = c("orange", "green"))
```
- A pesar de la diferencia, ¿será ésta significativa?


Parte 3. Regresión Logística
La regresión logística modela el comportamiento de la probabilidad del evento de interés:

log(p/1–p)=β0+βixi

La parte izquierda representa esa probabilidad pero en términos del odds. La parte derecha de la ecuación es igual a la ecuación de una recta, pero estamos modelando al logaritmo del odds. Veamos cómo calcularla en R:
```{r}
### semilla
set.seed(2019)

### primer modelo:
#data como subset
vars1=vol[,c("volunteer","sex")]

#regresion
rlog1=glm(volunteer~., data=vars1,family = binomial)

#resultado clásico:
summary(rlog1)
```

Veamos ahora el resultado con mejor formato:
```{r}
# recuerda poner: ```{r, results='asis'}
library(stargazer)
#resultado
stargazer(rlog1, type="text")
```

Los coeficientes, como se vió en la ecuación anterior, están modelando al logaritmo del odds de ser voluntario.

El resultado anterior ha usado a mujer como referencia: nos informa cuánto afecta al log odds de ser voluntario el ser hombre en comparación con ser mujer (la referencia). Ahora sabes que ser hombre disminuye la probabilidad de ser voluntario. Ajustemos la referencia para ver el efecto de mujer:

```{r}
# nueva referencia
vol$sex=relevel(vol$sex,ref = "male")
# rehago subset
vars1=vol[,c("volunteer","sex")]

rlog1=glm(volunteer~., data=vars1,family = binomial)
```
Los resultados van a continuación:
```{r}
#resultado
stargazer(rlog1,type="text")
```

Vemos que sexo tiene efecto, y el símbolo del coeficiente propone que el efecto es positivo. Ese valor, como modela a un logaritmo, no es fácil de interpretar. Pero, si le aplicas exponencial, hallarás un valor conocido:
```{r}
sexF=coef(rlog1)["sexfemale"]
exp(sexF)
```

Ahora sabemos que el efecto de sexo es significativo gracias a la regresión logística, algo que no sabíamos con las tablas de contingencia.


Además, con la regresión logística podemos tener predictores numéricos, lo que escapa de la utilidad de las tablas de contingencia:
```{r}
vars2=vol[,c("volunteer","sex","neuroticism")]
rlog2=glm(volunteer~., data=vars2,family = binomial)
vars3=vol[,c("volunteer","sex","neuroticism","extraversion")]
rlog3=glm(volunteer~., data=vars3,family = binomial)
```

Veamos todos:
```{r}
library(stargazer)
stargazer(rlog1,rlog2,rlog3,type ="text", no.space = F,digits =3,digit.separator="")
```

#1. Comparando modelos

Las tres regresiones presentan valores diferentes del criterio de información de Akaike (AIC), se considera que un modelo es mejor si tiene un AIC menor a los demás. Esto sugiere qu el tercer modelo es el mejor y el segundo el peor. Como los valores del AIC están muy cercanos confirmemos usando el test de razón de verosimilitud (likelihood ratio test -LRT):
```{r}
library(lmtest)
lrtest(rlog1,rlog2, rlog3)
```
O alternativamente:
```{r}
library(pander)
pander(lrtest(rlog1,rlog2, rlog3),caption = "LRT para los tres modelos")
```

Como vemos, pasar del modelo 1 al modelo 2 es no significativo (probabilidad es mayor a 0.05), por lo que no se rechaza la hipotesis nula de igualdad de modelos. Pero sí es significativo pasar del modelo 2 al modelo 3.


#2. Evaluando modelo seleccionado

Calculemos las probabilidades predecidas de voluntariado:
```{r}
predicted <- plogis(predict(rlog3, vars3[,-1]))
```
Veamos la matriz de confusión:
```{r}
library(InformationValue)
confusionMatrix(vars3$volunteer, predicted)
```
La antidiagonal debería ser 0s si fuera una predicción perfecta. Si un modelo es mejor, debe reducir sustantivamente ese error.


#Dos medidas importantes es saber qué tanto acertamos predecir el evento:
```{r}
sensitivity(actuals = as.numeric(vars3$volunteer),predictedScores = predicted)
```

#Y qué tanto acertamos predecir la no ocurrencia del evento:
```{r}
specificity(actuals = as.numeric(vars3$volunteer),predictedScores = predicted)
```

Si nos quedamos con este modelo, obtengamos sus coeficientes en odds ratio:
```{r}
exp(cbind(OR = coef(rlog3), confint(rlog3)))
```
Esto quiere decir que:

- Ser MUJER tiene un odds ratio mayor al del HOMBRE en 0.26.
- El nivel de neuroticismo no aumenta el odds ratio de ser voluntario.
- El nivel de extraversion aumenta el odds ratio de ser voluntario en 0.06.

Nótese que los valores que he escrito se calculan asi: 1-OR; de ahí que si un OR fuese menor a 1, como 0.87, diriamos que el efecto es de 0.13 sobre la dependiente.

#Preparemos las ecuaciones que nos dan las probabilidades a partir de los coeficientes de regresión:
Pr(VOLUNT=1|Xi)=exp(β0+β1SEXfemale+β2NEU+β3EXTRAV)1+exp(β0+β1SEX+β2NEU+β3EXTRAV)

#Cambiando betas:
Pr(VOLUNT=1|Xi)=exp(−1.35+0.23SEXfemale+0.006NEU+0.06EXTRAV)1+exp(−1.35+0.23SEXfemale+0.006NEU+0.06EXTRAV)

3. Prediciendo valores concretos
  - Predecir probabilidad de voluntariado de una mujer con nivel de neuroticismo=13 y extraversion=8:

```{r}
ndata <- data.frame(sex=factor(c("female")), 
                      neuroticism=13, extraversion=8)
predict(object = rlog3, newdata = ndata, type = "response")
```

Predecir probabilidad de voluntariado de una mujer y hombre con los mismos niveles anteriores de neuroticismo y extraversion.
```{r}
ndata <- data.frame(sex=factor(c("female","male")), 
                      neuroticism=13, extraversion=8)
predict(object = rlog3, newdata = ndata, type = "response")
```

Predecir probabilidad de voluntariado de dos mujeres, con nivel de neuroticismo de 13 y 10, y extraversion de 8 y 21, respectivamente:
```{r}
ndata <- data.frame(sex=factor(c("female","male")), 
                      neuroticism=c(13,10), extraversion=c(8,21))
predict(object = rlog3, newdata = ndata, type = "response")
```

4. Efectos Marginales
Recuerdese que tenemos en predicted las probabilidades de cada caso:
```{r}
head(predicted)
```
Pero NO sabemos cuando afecta cada variable la probabilidad de ser voluntario en promedio. Para ello pedimos efectos marginales.
```{r}
# interpracion usando marginal effects:
library(margins)
(model = margins(rlog3))
```
### Average marginal effects
### glm(formula = volunteer ~ ., family = binomial, data = vars3)
###  neuroticism extraversion sexfemale
###      0.00152      0.01585   0.05623

- Esto sí indica cuanto afecta cada variable la probabilidad de ser voluntario.

Para graficar veamos un resumen:
```{r}
(margins=summary(model))
```

Luego, aqui vemos efecto:
```{r}
library(ggplot2)
base= ggplot(margins,aes(x=factor, y=AME)) + geom_point()
base
```

Aqui el efecto y su intervalo de confianza:
```{r}
base +  geom_errorbar(aes(ymin=lower, ymax=upper))
```


Tarea para la casa:

Organize por provincia la data de la segunda vuelta entre PPk y KEIKO, tal que un columna indique quien ganó en esa provincia. Luego, use el indice de densidad del estado como predictores añadiendole una columna que indique si esa provincia es más urbana que rural según el censo 2007. A qué conclusión llega? Haga un reporte exhaustivo.
