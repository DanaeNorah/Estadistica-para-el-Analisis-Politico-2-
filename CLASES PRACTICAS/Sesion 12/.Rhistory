names(demo)=gsub("Â","",names(demo))
demo$Country=gsub("Â","",demo$Country)
demo$Country=trimws(demo$Country,whitespace = "[\\h\\v]") #PREGUNTAR CUAL ES LA DIFERENCIA ENTRE ESTE Y GSUB
# preparación
demo=demo[,-c(1)] #sin Rank
demo=demo[,-10]
demo[,-c(1,8,9)]=lapply(demo[,-c(1,8,9)], as.numeric) # a numerico
names(demo)[9]= 'Continent'
subdata=demo
row.names(subdata)=subdata$Country
subdata=na.omit(subdata)
# veamos que tenemos:
str(subdata)
set.seed(2020)
inputData=subdata[,c(3:7)]
g.dist = daisy(inputData, metric="gower")
fviz_nbclust(inputData, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
fviz_nbclust(inputData, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
res.pam = pam(g.dist,5,cluster.only = F)
res.agnes = hcut(g.dist, k = 5,hc_func='agnes',hc_method = "ward.D")
res.diana = hcut(g.dist, k = 5,hc_func='diana')
fviz_silhouette(res.pam)
fviz_silhouette(res.agnes)
fviz_silhouette(res.diana)
str(res.pam$silinfo)
# veamos solo algunos.
head(res.pam$silinfo$widths)
poorPAM=data.frame(res.pam$silinfo$widths)
poorPAM$country=row.names(poorPAM)
poorPAMcases=poorPAM[poorPAM$sil_width<0,'country']#me quedo con los negativos porque son los mas clusterizados
poorPAMcases
length(poorPAMcases)
# agnes
poorAGNES=data.frame(res.agnes$silinfo$widths)
poorAGNES$country=row.names(poorAGNES)
poorAGNEScases=poorAGNES[poorAGNES$sil_width<0,'country']
#diana:
poorDIANA=data.frame(res.diana$silinfo$widths)
poorDIANA$country=row.names(poorDIANA)
poorDIANAcases=poorDIANA[poorDIANA$sil_width<0,'country']
intersect(poorAGNEScases,poorPAMcases)
setdiff(poorAGNEScases,poorPAMcases)
setdiff(poorPAMcases,poorAGNEScases)
union(poorPAMcases,poorAGNEScases)
proyeccion = cmdscale(g.dist, k=4,add = T) # k is the number of dim
# data frame prep:
inputData$dim1 <- proyeccion$points[,1]
inputData$dim2 <- proyeccion$points[,2]
base= ggplot(inputData,aes(x=dim1, y=dim2,label=row.names(inputData)))
base + geom_text(size=2)
inputData$pam=as.factor(res.pam$clustering)
inputData$agnes=as.factor(res.agnes$cluster)
inputData$diana=as.factor(res.diana$cluster)
# Estimado limites:
min(inputData[,c('dim1','dim2')]); max(inputData[,c('dim1','dim2')])
#PAM
limites=c(-0.7,0.7)
base= ggplot(inputData,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
base + geom_point(size=2, aes(color=pam))  + labs(title = "PAM")
#AGNES
base + geom_point(size=2, aes(color=agnes)) + labs(title = "AGNES")
#DIANA
base + geom_point(size=2, aes(color=diana)) + labs(title = "DIANA")
#### euclidea!!
g.dist.cmd = daisy(inputData[,c('dim1','dim2')], metric = 'euclidean')
library(dbscan)
kNNdistplot(g.dist.cmd, k=5)
library(fpc)
db.cmd = dbscan(g.dist.cmd, eps=0.06, MinPts=5,method = 'dist')
db.cmd
inputData$dbCMD=as.factor(db.cmd$cluster)
library(ggrepel)
base= ggplot(inputData,aes(x=dim1, y=dim2)) + ylim(limites) + xlim(limites) + coord_fixed()
dbplot= base + geom_point(aes(color=dbCMD))
dbplot
dbplot + geom_text_repel(size=5,aes(label=row.names(inputData)))
LABEL=ifelse(inputData$dbCMD==0,row.names(inputData),"")
dbplot + geom_text_repel(aes(label=LABEL),
size=5,
direction = "y", ylim = 0.45,
angle=45,
segment.colour = "grey")
# agnes
poorAGNES=data.frame(res.agnes$silinfo$widths)
poorAGNES$country=row.names(poorAGNES)
poorAGNEScases=poorAGNES[poorAGNES$sil_width<0,'country']
#diana:
poorDIANA=data.frame(res.diana$silinfo$widths)
poorDIANA$country=row.names(poorDIANA)
poorDIANAcases=poorDIANA[poorDIANA$sil_width<0,'country']
poorAGNEScases
poorDIANAcases
inputData$pam=as.factor(res.pam$clustering)
inputData$agnes=as.factor(res.agnes$cluster)
inputData$diana=as.factor(res.diana$cluster)
library(fpc)
db.cmd = dbscan(g.dist.cmd, eps=0.06, MinPts=5,method = 'dist')
db.cmd
inputData$dbCMD=as.factor(db.cmd$cluster)
View(inputData)
inputData$dbCMD[inputData$dbCMD==1,'Country']
inputData[inputData$dbCMD==1,'Country']
inputData[inputData$dbCMD==0,'Country']
inputData[inputData$dbCMD==1,'Country']
inputData[inputData$dbCMD==1,'row.names']
inputData[inputData$dbCMD==1,row.names]
inputData[inputData$dbCMD==1,row.names()]
subdata$dbCMD=as.factor(db.cmd$cluster)
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo <- htmltab(doc = demolink, which =demopath)
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo <- htmltab(doc = demolink, which =demopath)
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo <- htmltab(doc = demolink, which =demopath)
# limpieza
library(stringr)
library(magrittr)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo <- htmltab(doc = demolink, which =demopath)
demo=htmltab(doc=demolink,wich=demopath)
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo=htmltab(doc=demolink,wich=demopath)
particion=subsubdata$particion
library(htmltab) #para scrapear
library(stringr) #para limpieza de columnas
library(readr) #para extraer un único numero de la columna
library(rio) #para importar
library(cluster) #clustering
library(plyr) #aggregate, funcion each
library(psych) #para hacer tablas comparadas
library(knitr) #para generar tablas html
library(kableExtra) #para generar tablas html
library(factoextra) #visualización de clusters
library(ggrepel) #para que las etiquetas de los graficos no se superpongan
library(dplyr)
library(car) #recodificacion
library(magrittr)
library(foreign)
library(cluster)
library(ggrepel)
library(foreign)
seguridad=import('https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/seguridadUSA.xlsx')
subdata=seguridad
str(subdata)
#a. Los nombres de cada caso aparezcan en las gráficas:
row.names(subdata)=subdata$estado
# alternativa a complete.cases:
subdata=na.omit(subdata)
set.seed(2020)
library(cluster)
# usar en C() las dimensiones de interes:
g.dist = daisy(subdata[,c(2:4)], metric="gower")
#CALCULAMOS LAS DISTANCIAS CON DAYS
#NÚMERO DE CLUSTER PARA PARTICIÓN (colocamos pam)
fviz_nbclust(subdata[,c(2:4)], pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
#Número de clusters para jerarquización (colocamos hcut) #solo uno para jerarquico
fviz_nbclust(subdata[,c(2:4)], hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 3,hc_func='diana') #Indicamos 3 por el resultado anterior
particion=subsubdata$particion
# Revisamos cómo se ve ese elemento widths
head(particion$silinfo$widths)
# Creamos un data.frame que sea equivalente a ese elemento
widths.particion=data.frame(particion$silinfo$widths)
# Creamos un vector que sea el nombre de la región. Lo jalamos del nombre de la fila./ para que salga el nombre en el grafico
widths.particion$Id=row.names(widths.particion)
View(widths.particion)
particion = pam(g.dist,3,cluster.only = F) #Indicamos 3 por el resultado anterior
aglomerativo = hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D") #Indicamos 3 por el resultado anterior
divisivo = hcut(g.dist, k = 3,hc_func='diana') #Indicamos 3 por el resultado anterior
subdata$clusterPT= particion$cluster
fviz_silhouette(particion)
fviz_silhouette(aglomerativo)
fviz_silhouette(divisivo)
View(particion)
View(subdata)
View(widths.particion)
library(rio)
basefinal=import('https://raw.githubusercontent.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/master/TRABAJO/basefinal.csv')
library(car)
#Para recodificar usamos la funcion recode
basefinal$Autonomia1 <- recode(basefinal$Autonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Autonomia1 <-as.factor(basefinal$Autonomia1)
basefinal$Autonomia1=factor(basefinal$Autonomia1,
levels = levels(basefinal$Autonomia1),
labels = c("5","4","3","2","1"),
ordered = T)
basefinal$Autonomia1 <-as.numeric(basefinal$Autonomia1)
basefinal$Violencia
basefinal$Violencia1 <- recode(basefinal$Violencia, "0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Violencia1 <-as.factor(basefinal$Violencia1)
basefinal$Violencia1=factor(basefinal$Violencia1,
levels = levels(basefinal$Violencia1),
labels = c("4","3","2","1"),
ordered = T)
basefinal$Violencia1 <-as.numeric(basefinal$Violencia1)
subdata <-basefinal[,c(5:12)]
library(polycor)
matriz<-hetcor(subdata)
matriz_corr<- matriz$correlations
library(ggcorrplot)
ggcorrplot(matriz_corr)
ggcorrplot(matriz_corr,
p.mat = cor_pmat(matriz_corr),
insig = "blank")
library(psych)
KMO(matriz_corr)
#Chequear el overall MSA, que sea mayor a 0.5
#Si es > a 0.5, el EFA va bien
cortest.bartlett(matriz_corr,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(matriz_corr)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
#Este comando y proximo son insumo basico para hacer el factorial
#Vemos el diagrama de sedimentacion
library(GPArotation)
factorial <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
#nfactors: 3 por el paso anterior
print(factorial$loadings)
print(factorial$loadings,cutoff = 0.5)
fa.diagram(factorial)
factorial$crms
#Es menor a 0.05. Valor 0.049
factorial$RMSEA
#Mayor a 0.05. Valor: 0.063
factorial$TLI
#Es mayor a 0.9. Valor 0.942
sort(factorial$communality)
#Secundaria, CuentaF, LibertadMov, AccesoJ
sort(factorial$complexity)
factorial_casos<-as.data.frame(factorial$scores)
head(factorial_casos)
subdata$factor1<- factorial_casos$MR1
subdata$factor2<- factorial_casos$MR2
subdata$factor3<- factorial_casos$MR3
summary(factorial_casos)
library(rio)
basefinal=import('https://raw.githubusercontent.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/master/TRABAJO/basefinal.csv')
library(car)
#Para recodificar usamos la funcion recode
basefinal$Autonomia1 <- recode(basefinal$Autonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Autonomia1 <-as.factor(basefinal$Autonomia1)
basefinal$Autonomia1=factor(basefinal$Autonomia1,
levels = levels(basefinal$Autonomia1),
labels = c("5","4","3","2","1"),
ordered = T)
basefinal$Autonomia1 <-as.numeric(basefinal$Autonomia1)
basefinal$Violencia
basefinal$Violencia1 <- recode(basefinal$Violencia, "0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Violencia1 <-as.factor(basefinal$Violencia1)
basefinal$Violencia1=factor(basefinal$Violencia1,
levels = levels(basefinal$Violencia1),
labels = c("4","3","2","1"),
ordered = T)
basefinal$Violencia1 <-as.numeric(basefinal$Violencia1)
basefinal$LibertadMov1= 100 - basefinal$LibertadMov
basefinal$AccesoJ1= 100 - basefinal$AccesoJ
subdata <-basefinal[,c(5,8:14)]
library(polycor)
matriz<-hetcor(subdata)
matriz_corr<- matriz$correlations
library(ggcorrplot)
ggcorrplot(matriz_corr)
ggcorrplot(matriz_corr,
p.mat = cor_pmat(matriz_corr),
insig = "blank")
library(psych)
KMO(matriz_corr)
#Chequear el overall MSA, que sea mayor a 0.5
#Si es > a 0.5, el EFA va bien
cortest.bartlett(matriz_corr,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(matriz_corr)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
#Este comando y proximo son insumo basico para hacer el factorial
#Vemos el diagrama de sedimentacion
library(GPArotation)
factorial <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
#nfactors: 3 por el paso anterior
print(factorial$loadings)
print(factorial$loadings,cutoff = 0.5)
fa.diagram(factorial)
factorial$crms
#Es menor a 0.05. Valor 0.049
factorial$RMSEA
#Mayor a 0.05. Valor: 0.063
factorial$TLI
#Es mayor a 0.9. Valor 0.942
sort(factorial$communality)
#Secundaria, CuentaF, LibertadMov, AccesoJ
sort(factorial$complexity)
factorial_casos<-as.data.frame(factorial$scores)
head(factorial_casos)
subdata$factor1<- factorial_casos$MR1
subdata$factor2<- factorial_casos$MR2
subdata$factor3<- factorial_casos$MR3
summary(factorial_casos)
library(polycor)
matriz<-hetcor(subdata)
matriz_corr<- matriz$correlations
library(ggcorrplot)
ggcorrplot(matriz_corr)
library(rio)
basefinal=import('https://raw.githubusercontent.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/master/TRABAJO/basefinal.csv')
library(car)
#Para recodificar usamos la funcion recode
basefinal$Autonomia1 <- recode(basefinal$Autonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Autonomia1 <-as.factor(basefinal$Autonomia1)
basefinal$Autonomia1=factor(basefinal$Autonomia1,
levels = levels(basefinal$Autonomia1),
labels = c("5","4","3","2","1"),
ordered = T)
basefinal$Autonomia1 <-as.numeric(basefinal$Autonomia1)
basefinal$Violencia
basefinal$Violencia1 <- recode(basefinal$Violencia, "0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Violencia1 <-as.factor(basefinal$Violencia1)
basefinal$Violencia1=factor(basefinal$Violencia1,
levels = levels(basefinal$Violencia1),
labels = c("4","3","2","1"),
ordered = T)
basefinal$Violencia1 <-as.numeric(basefinal$Violencia1)
basefinal$LibertadMov1= 100 - basefinal$LibertadMov
basefinal$AccesoJ1= 100 - basefinal$AccesoJ
subdata <-basefinal[,c(5,8:14)]
library(polycor)
matriz<-hetcor(subdata)
matriz_corr<- matriz$correlations
library(ggcorrplot)
ggcorrplot(matriz_corr)
ggcorrplot(matriz_corr,
p.mat = cor_pmat(matriz_corr),
insig = "blank")
library(psych)
KMO(matriz_corr)
#Chequear el overall MSA, que sea mayor a 0.5
#Si es > a 0.5, el EFA va bien
cortest.bartlett(matriz_corr,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(matriz_corr)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
#Este comando y proximo son insumo basico para hacer el factorial
#Vemos el diagrama de sedimentacion
library(GPArotation)
factorial <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
#nfactors: 3 por el paso anterior
print(factorial$loadings)
print(factorial$loadings,cutoff = 0.5)
fa.diagram(factorial)
factorial$crms
#Es menor a 0.05. Valor 0.049
factorial$RMSEA
#Mayor a 0.05. Valor: 0.063
factorial$TLI
#Es mayor a 0.9. Valor 0.942
sort(factorial$communality)
#Secundaria, CuentaF, LibertadMov, AccesoJ
sort(factorial$complexity)
factorial_casos<-as.data.frame(factorial$scores)
head(factorial_casos)
subdata$factor1<- factorial_casos$MR1
subdata$factor2<- factorial_casos$MR2
subdata$factor3<- factorial_casos$MR3
summary(factorial_casos)
library(rio)
basefinal=import('https://raw.githubusercontent.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/master/TRABAJO/basefinal.csv')
library(car)
#Para recodificar usamos la funcion recode
basefinal$Autonomia1 <- recode(basefinal$Autonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Autonomia1 <-as.factor(basefinal$Autonomia1)
basefinal$Autonomia1=factor(basefinal$Autonomia1,
levels = levels(basefinal$Autonomia1),
labels = c("5","4","3","2","1"),
ordered = T)
basefinal$Autonomia1 <-as.numeric(basefinal$Autonomia1)
basefinal$Violencia
basefinal$Violencia1 <- recode(basefinal$Violencia, "0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Violencia1 <-as.factor(basefinal$Violencia1)
basefinal$Violencia1=factor(basefinal$Violencia1,
levels = levels(basefinal$Violencia1),
labels = c("4","3","2","1"),
ordered = T)
basefinal$Violencia1 <-as.numeric(basefinal$Violencia1)
subdata <-basefinal[,c(5:12)]
library(polycor)
matriz<-hetcor(subdata)
matriz_corr<- matriz$correlations
library(ggcorrplot)
ggcorrplot(matriz_corr)
ggcorrplot(matriz_corr,
p.mat = cor_pmat(matriz_corr),
insig = "blank")
library(psych)
KMO(matriz_corr)
#Chequear el overall MSA, que sea mayor a 0.5
#Si es > a 0.5, el EFA va bien
cortest.bartlett(matriz_corr,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(matriz_corr)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
#Este comando y proximo son insumo basico para hacer el factorial
#Vemos el diagrama de sedimentacion
library(GPArotation)
factorial <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
#nfactors: 3 por el paso anterior
print(factorial$loadings)
print(factorial$loadings,cutoff = 0.5)
fa.diagram(factorial)
factorial$crms
#Es menor a 0.05. Valor 0.049
factorial$RMSEA
#Mayor a 0.05. Valor: 0.063
factorial$TLI
#Es mayor a 0.9. Valor 0.942
sort(factorial$communality)
#Secundaria, CuentaF, LibertadMov, AccesoJ
sort(factorial$complexity)
factorial_casos<-as.data.frame(factorial$scores)
head(factorial_casos)
subdata$factor1<- factorial_casos$MR1
subdata$factor2<- factorial_casos$MR2
subdata$factor3<- factorial_casos$MR3
summary(factorial_casos)
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
library(car)
data$Autonomia=recode(data$Autonomia,"0=1;0.25=2;0.5=3;0.75=4;1=5")
table(data$Autonomia )
#Le asignamos etiquetas a los valores
data$Violencia=recode(data$Violencia,"0.25=1;0.5=2;0.75=3;1=4")
table(data$Violencia)
subdata= data[,c(3,4,5,6,7,8,10)]
#subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
#subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero
subdata$Autonomia= 100 - subdata$Autonomia
subdata$Violencia= 100 - subdata$Violencia
#subdata$LibertadMov= 100 - subdata$LibertadMov
#subdata$AccesoJ= 100 - subdata$AccesoJ
#subdata$Desempleo= 100 - subdata$Desempleo
str(subdata)
#scale(subdata$Desempleo,scale = T)*100
# esta es:
#thesubdata=na.omit(thesubdata)
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
#Evaluando significancia:
ggcorrplot(corMatrix,
p.mat = cor_pmat(corMatrix),
insig = "blank")
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
library(psych)
psych::KMO(corMatrix)
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa)
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
#¿Qué nombres les darías?
as.data.frame(resfa$scores)
HappyDemoFA=cbind(HappyDemo[1],as.data.frame(resfa$scores))
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/basefinal.csv'
data = import(link)
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
setwd("C:/Users/Equipo/Desktop/CURSOS PUCP/6 SEXTO CICLO/Estadística para el Análisis Político 2/Estadistica-para-el-Analisis-Politico-2-/CLASES PRACTICAS/Sesion 12")
library(htmltab)
#base 1
detach("package:htmltab", unload = TRUE)
library(rio)
