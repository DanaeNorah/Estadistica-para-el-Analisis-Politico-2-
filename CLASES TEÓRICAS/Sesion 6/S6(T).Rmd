
SESION 6 - CLASE TEORICA

Análisis de Conglomerados: Estrategia de Jerarquizacion

La jerarquización busca clusterizar por etapas, hasta que todas las posibilidades de clusterizacion sean visible. Este enfoque tiene dos familias de algoritmos:
- Aglomerativos
- Divisivos

```{r}
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo<- htmltab(doc = demolink, which =demopath)
```

```{r}
# limpieza
library(stringr)
library(magrittr)
names(demo)=str_split(names(demo),">>",simplify = T)[,1]%>%gsub('\\s','',.)

demo[,-c(1,8,9)]=lapply(demo[,-c(1,8,9)], trimws,whitespace = "[\\h\\v]") # no blanks

names(demo)=gsub("Â","",names(demo))
demo$Country=gsub("Â","",demo$Country)
```

```{r}
demo=demo[,-10]
```

```{r}
# preparación
demo=demo[,-c(1)] #sin Rank
demo[,-c(1,8,9)]=lapply(demo[,-c(1,8,9)], as.numeric) # a numerico
```

```{r}
# veamos que tenemos:
str(demo)
```
ESTRATETGIA AGLOMERATIVA 
- NO hay clusters, tiene limite en cuanto a cantidad de datos
- Se parte por considerar cada caso(fila) como un CLUSTER, para de ahi ir creando MINICLUSTERS hasta que todos los casos sean un    solo cluster. El proceso va mostrando que tanto esfuerzo toma juntar los elementos cluster tras cluster.

Antes de proseguir, nos aseguramos que:
```{r}
#Los nombres de cada caso aparezcan en las gráficas:
row.names(demo)=demo$Country
```
Solo trabajemos con data sin valores perdidos:
```{r}
# alternativa a complete.cases:
demo=na.omit(demo)
```

1. Calcular distancias es eses

PASO 1: calcular distancias
```{r}
library(cluster)
g.dist = daisy(demo[,c(3:7)], metric="gower")
```

2. Decidir linkages
Esta es la distancia entre los elementos, tenemos que decidir como se irá calculando la distancia entre los clusters que se van formando (ya no son casos individuales). Los tres mas simples metodos:
 ##como se usa uno de los nuevos con los otros, distancia para unir entre grupos o clusters nuevos

- Linkage tipo SINGLE. (cercanos)

- Linkage tipo COMPLETE.(lejanos)

- Linkage tipo AVERAGE (ver distancia de todos los pares y promedios de todas las distnacias)(sumas y divides)
 
-Otro metodo adicional, y muy eficiente, es el de WARD. Al final, lo que necesitamos saber cual de ellos nos entregará una mejor propuesta de clusters. Usemos este para nuestro caso.

3. Calcular clusters
La función hcut es la que usaremos para el método jerarquico, y el algoritmo aglomerativo se emplea usando agnes. El linkage será ward (aquí ward.D):
```{r}
library(factoextra)

res.agnes <- hcut(g.dist, k =4,hc_func='agnes',hc_method = "ward.D")

demo$clustAG=res.agnes$cluster
```

4. Comparar
Veamos qué tanto se parece a la clasificación de The Economist:
```{r}
table(demo$Regimetype,demo$clustAG,dnn = c('TheEconomist','clustAgg'))
```
5. Visualizar

El dendograma nos muestra el proceso de conglomeración:
```{r}
# Visualize
fviz_dend(res.agnes,k=4, cex = 0.7, horiz = T)
```
El eje ‘Height’ nos muestra el “costo” de conglomerar.


ESTATREGIA DVISIVA 
 - el cluster es todo
 - Esta estrategia comienza con todos los casos como un gran cluster; para de ahi dividir en clusters más pequeños.
 - Comparando con el proceso anterior, el paso 1 no es necesario repetirlo, el paso 2 no corresponde a esta técnica, por lo que      vamos directo al paso 3:

3. Calcular clusters
La función hcut es la que usaremos para el método jerarquico, y el algoritmo divisivo se emplea usando diana:
```{r}
res.diana <- hcut(g.dist, k = 4,hc_func='diana')
demo$clustDIV=res.diana$cluster
```
4. Comparar
- Veamos qué tanto se parece a la clasificación de The Economist:
```{r}
table(demo$Regimetype,demo$clustDIV,dnn = c('TheEconomist','clustDiv'))
```
5. Visualizar
- El dendograma nos muestra el proceso de conglomeración:
```{r}
fviz_dend(res.diana, cex = 0.7,horiz = T) #cex es para tamaño o expansion
```
Nota que en esta técnica se ve a todos los elementos (casos) asignados a algun cluster.







