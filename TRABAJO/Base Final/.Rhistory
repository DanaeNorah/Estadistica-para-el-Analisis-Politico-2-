table(data$MLViolencia)
library(BBmisc)
data$DesempleoMuj= normalize(data$DesempleoMuj,
method = "range",
margin=2, # by column
range = c(0, 100),)
data$DesempleoMuj=round(data$DesempleoMuj,2)
subdata= data[,c(3,4,5,6,7,8,9,10)]
#subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
#subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero
#subdata$LibertadMov= 100 - subdata$LibertadMov
#subdata$ConfianzaSJ= 100 - subdata$ConfianzaSJ
subdata$DesempleoMuj= 100 - subdata$DesempleoMuj
str(subdata)
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
#Evaluando significancia:
ggcorrplot(corMatrix,
p.mat = cor_pmat(corMatrix),
insig = "blank")
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
library(psych)
psych::KMO(corMatrix)
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa)
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
factoriales=as.data.frame(resfa$scores)
head(factoriales)
subdata$factor1<- factoriales$MR1
subdata$factor2<- factoriales$MR2
subdata$factor3<- factoriales$MR3
summary(factoriales)
subdata=cbind(data[,c(1,2)],subdata)
library(fpc)
library(cluster)
library(dbscan)
# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]
g.dist.cmd = daisy(subdata[,c(11:13)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
abline(h= 0.62,col='red')
res.DB=fpc::dbscan(g.dist.cmd, eps=0.62, MinPts=3,method = 'dist')
subdata$clustDB=as.factor(res.DB$cluster)
aggregate(cbind(factor1, factor2,factor3) # dependientes
~ clustDB, # nivel
data = subdata,    # data
max)            # operacion
library(BBmisc)
subdata$factor1=normalize(subdata$factor1,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor2=normalize(subdata$factor2,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor3=normalize(subdata$factor3,
method = "range",
margin=2, # by column
range = c(0, 100))
plot(subdata$DesigualdadGenero,subdata$factor1)
plot(subdata$DesigualdadGenero,subdata$factor2)
plot(subdata$DesigualdadGenero,subdata$factor3)
hipotesis = formula(DesigualdadGenero ~ factor1)
regresion=lm(hipotesis,data=subdata)
summary(regresion)
hipotesis1 = formula(DesigualdadGenero ~ factor2)
regresion1=lm(hipotesis1,data=subdata)
summary(regresion1)
hipotesis2 = formula(DesigualdadGenero ~ factor3)
regresion2=lm(hipotesis2,data=subdata)
summary(regresion2)
hipotesis3 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3)
regresion3=lm(hipotesis3,data=subdata[,-c(1)])
summary(regresion3)
# linea roja debe tender a horizontal
plot(regresion3, 1)
# linea roja debe tender a horizontal
plot(regresion3, 3)
library(lmtest)
# null: modelo homocedastico
bptest(regresion3)
# puntos cerca a la diagonal
plot(regresion3, 2)
shapiro.test(regresion3$residuals)
library(DescTools)
VIF(regresion3) # > 5 es problematico
hipotesis4 = formula(DesigualdadGenero ~ .)
#como son todas las demas las v. independientes se pone "."
regre=lm(hipotesis4,data=subdata[,-c(1)])
summary(regre)
hipotesis5 = formula(DesigualdadGenero ~ MLAutonomia + VozPolitica + DesempleoMuj + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre1=lm(hipotesis5,data=subdata[,-c(1)])
summary(regre1)
hipotesis6 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica  + LibertadMov + DesempleoMuj + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis6,data = subdata[,-c(1)])
summary(regre2)
hipotesis7 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica  + LibertadMov + DesempleoMuj + ConfianzaSJ + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre3=lm(hipotesis7,data = subdata[,-c(1)])
summary(regre3)
hipotesis8 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre4=lm(hipotesis8,data=subdata[,-c(1)])
summary(regre4)
hipotesis9 = formula(DesigualdadGenero ~ MLAutonomia  + LibertadMov + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis2,data=subdata[,-c(1)])
summary(regre2)
hipotesis10 = formula(DesigualdadGenero ~ MLAutonomia + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis10,data=subdata[,-c(1)])
summary(regre2)
table(basefinal$Autonomia1)
table(data$MLAutonomia)
table(data$MLAutonomia)
table(basefinal$Autonomia1)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("5","4","3","2","1"),
ordered = F)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("5","4","3","2","1"),
ordered = T)
table(data$MLAutonomia)
table(data$MLAutonomia)
table(data$MLAutonomia)
table(basefinal$Autonomia1)
library(car)
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("1","2","3","4","5"),
ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
data=na.omit(data)
library(car)
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("1","2","3","4","5"),
ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
#Le asignamos etiquetas a los valores
data$MLViolencia <- recode(data$MLViolencia,"0.25=0.75 ; 0.5=0.5 ; 0.75=0.25")
data$MLViolencia <-as.factor(data$MLViolencia)
data$MLViolencia=factor(data$MLViolencia,
levels = levels(data$MLViolencia),
labels = c("3","2","1"),
ordered = T)
data$MLViolencia <-as.numeric(data$MLViolencia)
table(data$MLViolencia)
library(BBmisc)
data$DesempleoMuj= normalize(data$DesempleoMuj,
method = "range",
margin=2, # by column
range = c(0, 100),)
data$DesempleoMuj=round(data$DesempleoMuj,2)
subdata= data[,c(3,4,5,6,7,8,9,10)]
#subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
#subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero
#subdata$LibertadMov= 100 - subdata$LibertadMov
#subdata$ConfianzaSJ= 100 - subdata$ConfianzaSJ
subdata$DesempleoMuj= 100 - subdata$DesempleoMuj
str(subdata)
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
#Evaluando significancia:
ggcorrplot(corMatrix,
p.mat = cor_pmat(corMatrix),
insig = "blank")
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
library(psych)
psych::KMO(corMatrix)
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa)
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
factoriales=as.data.frame(resfa$scores)
head(factoriales)
subdata$factor1<- factoriales$MR1
subdata$factor2<- factoriales$MR2
subdata$factor3<- factoriales$MR3
summary(factoriales)
subdata=cbind(data[,c(1,2)],subdata)
library(fpc)
library(cluster)
library(dbscan)
# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]
g.dist.cmd = daisy(subdata[,c(11:13)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
abline(h= 0.62,col='red')
res.DB=fpc::dbscan(g.dist.cmd, eps=0.62, MinPts=3,method = 'dist')
subdata$clustDB=as.factor(res.DB$cluster)
aggregate(cbind(factor1, factor2,factor3) # dependientes
~ clustDB, # nivel
data = subdata,    # data
max)            # operacion
library(BBmisc)
subdata$factor1=normalize(subdata$factor1,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor2=normalize(subdata$factor2,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor3=normalize(subdata$factor3,
method = "range",
margin=2, # by column
range = c(0, 100))
plot(subdata$DesigualdadGenero,subdata$factor1)
plot(subdata$DesigualdadGenero,subdata$factor2)
plot(subdata$DesigualdadGenero,subdata$factor3)
hipotesis = formula(DesigualdadGenero ~ factor1)
regresion=lm(hipotesis,data=subdata)
summary(regresion)
hipotesis1 = formula(DesigualdadGenero ~ factor2)
regresion1=lm(hipotesis1,data=subdata)
summary(regresion1)
hipotesis2 = formula(DesigualdadGenero ~ factor3)
regresion2=lm(hipotesis2,data=subdata)
summary(regresion2)
hipotesis3 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3)
regresion3=lm(hipotesis3,data=subdata[,-c(1)])
summary(regresion3)
# linea roja debe tender a horizontal
plot(regresion3, 1)
# linea roja debe tender a horizontal
plot(regresion3, 3)
library(lmtest)
# null: modelo homocedastico
bptest(regresion3)
# puntos cerca a la diagonal
plot(regresion3, 2)
shapiro.test(regresion3$residuals)
library(DescTools)
VIF(regresion3) # > 5 es problematico
hipotesis4 = formula(DesigualdadGenero ~ .)
#como son todas las demas las v. independientes se pone "."
regre=lm(hipotesis4,data=subdata[,-c(1)])
summary(regre)
hipotesis5 = formula(DesigualdadGenero ~ MLAutonomia + VozPolitica + DesempleoMuj + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre1=lm(hipotesis5,data=subdata[,-c(1)])
summary(regre1)
hipotesis6 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica  + LibertadMov + DesempleoMuj + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis6,data = subdata[,-c(1)])
summary(regre2)
hipotesis7 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica  + LibertadMov + DesempleoMuj + ConfianzaSJ + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre3=lm(hipotesis7,data = subdata[,-c(1)])
summary(regre3)
hipotesis8 = formula(DesigualdadGenero ~ MLAutonomia+ VozPolitica + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre4=lm(hipotesis8,data=subdata[,-c(1)])
summary(regre4)
hipotesis9 = formula(DesigualdadGenero ~ MLAutonomia  + LibertadMov + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis2,data=subdata[,-c(1)])
summary(regre2)
hipotesis10 = formula(DesigualdadGenero ~ MLAutonomia + CuentaF)
#como son todas las demas las v. independientes se pone "."
regre2=lm(hipotesis10,data=subdata[,-c(1)])
summary(regre2)
library(car)
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("1","2","3","4","5"),
ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
data=na.omit(data)
library(car)
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("1","2","3","4","5"),
ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
#Le asignamos etiquetas a los valores
data$MLViolencia <- recode(data$MLViolencia,"0.25=0.75 ; 0.5=0.5 ; 0.75=0.25")
data$MLViolencia <-as.factor(data$MLViolencia)
data$MLViolencia=factor(data$MLViolencia,
levels = levels(data$MLViolencia),
labels = c("3","2","1"),
ordered = T)
data$MLViolencia <-as.numeric(data$MLViolencia)
table(data$MLViolencia)
library(BBmisc)
data$DesempleoMuj= normalize(data$DesempleoMuj,
method = "range",
margin=2, # by column
range = c(0, 100),)
data$DesempleoMuj=round(data$DesempleoMuj,2)
subdata= data[,c(3,4,5,6,7,8,9,10)]
#subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
#subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero
#subdata$LibertadMov= 100 - subdata$LibertadMov
#subdata$ConfianzaSJ= 100 - subdata$ConfianzaSJ
subdata$DesempleoMuj= 100 - subdata$DesempleoMuj
str(subdata)
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
View(data)
library(rio)
basefinal=import('https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv')
basefinal=na.omit(basefinal)
library(car)
#Para recodificar usamos la funcion recode
basefinal$Autonomia1 <- recode(basefinal$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
basefinal$Autonomia1 <-as.factor(basefinal$Autonomia1)
basefinal$Autonomia1=factor(basefinal$Autonomia1,
levels = levels(basefinal$Autonomia1),
labels = c("5","4","3","2","1"),
ordered = T)
basefinal$Autonomia1 <-as.numeric(basefinal$Autonomia1)
View(basefinal)
View(basefinal)
library(rio)
link='https://github.com/DanaeNorah/Estadistica-para-el-Analisis-Politico-2-/raw/master/TRABAJO/Base%20Final/basefinal.csv'
data = import(link)
summary(data)
row.names(data)=data$Pais
data=na.omit(data)
library(car)
data$MLMLAutonomia <- recode(data$MLAutonomia, "0=1 ; 0.25=0.75 ; 0.5=0.5 ; 0.75=0.25 ; 1=0")
data$MLAutonomia <-as.factor(data$MLAutonomia)
data$MLAutonomia=factor(data$MLAutonomia,
levels = levels(data$MLAutonomia),
labels = c("5","4","3","2","1"),
ordered = T)
data$MLAutonomia <-as.numeric(data$MLAutonomia)
table(data$MLAutonomia)
#Le asignamos etiquetas a los valores
data$MLViolencia <- recode(data$MLViolencia,"0.25=0.75 ; 0.5=0.5 ; 0.75=0.25")
data$MLViolencia <-as.factor(data$MLViolencia)
data$MLViolencia=factor(data$MLViolencia,
levels = levels(data$MLViolencia),
labels = c("3","2","1"),
ordered = T)
data$MLViolencia <-as.numeric(data$MLViolencia)
table(data$MLViolencia)
subdata= data[,c(3,4,5,6,7,8,10)]
#subdata$DesigualdadGenero=subdata$DesigualdadGenero *100
#subdata$DesigualdadGenero= 100 - subdata$DesigualdadGenero
subdata$LibertadMov= 100 - subdata$LibertadMov
subdata$ConfianzaSJ= 100 - subdata$ConfianzaSJ
str(subdata)
# esta es:
library(polycor)
corMatrix=polycor::hetcor(subdata)$correlations
#Sin evaluar significancia:
library(ggcorrplot)
ggcorrplot(corMatrix)
#Evaluando significancia:
ggcorrplot(corMatrix,
p.mat = cor_pmat(corMatrix),
insig = "blank")
#te sirve para redondear a dos decimales, pero si se corresolo "matriz_corr" es para sacar
round(corMatrix, 2)
library(psych)
psych::KMO(corMatrix)
cortest.bartlett(corMatrix,n=nrow(subdata))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(subdata,fm = 'ML', fa = 'fa')
library(GPArotation)
resfa <- fa(subdata,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa)
#¿La Raíz del error cuadrático medio corregida está cerca a cero?
resfa$crms
#¿La Raíz del error cuadrático medio de aproximación es menor a 0.05?
resfa$RMSEA
#¿El índice de Tucker-Lewis es mayor a 0.9?
resfa$TLI
#¿Qué variables aportaron mas a los factores?
sort(resfa$communality)
#¿Qué variables contribuyen a mas de un factor?
sort(resfa$complexity)
factoriales=as.data.frame(resfa$scores)
head(factoriales)
subdata$factor1<- factoriales$MR1
subdata$factor2<- factoriales$MR2
subdata$factor3<- factoriales$MR3
summary(factoriales)
subdata=cbind(data[,c(1,2)],subdata)
library(fpc)
library(cluster)
library(dbscan)
# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]
g.dist.cmd = daisy(subdata[,c(10:12)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
abline(h= 0.62,col='red')
res.DB=fpc::dbscan(g.dist.cmd, eps=0.62, MinPts=3,method = 'dist')
subdata$clustDB=as.factor(res.DB$cluster)
aggregate(cbind(factor1, factor2,factor3) # dependientes
~ clustDB, # nivel
data = subdata,    # data
max)            # operacion
library(BBmisc)
subdata$factor1=normalize(subdata$factor1,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor2=normalize(subdata$factor2,
method = "range",
margin=2, # by column
range = c(0, 100))
subdata$factor3=normalize(subdata$factor3,
method = "range",
margin=2, # by column
range = c(0, 100))
plot(subdata$DesigualdadGenero,subdata$factor1)
plot(subdata$DesigualdadGenero,subdata$factor2)
plot(subdata$DesigualdadGenero,subdata$factor3)
hipotesis = formula(DesigualdadGenero ~ factor1)
regresion=lm(hipotesis,data=subdata)
summary(regresion)
hipotesis1 = formula(DesigualdadGenero ~ factor2)
regresion1=lm(hipotesis1,data=subdata)
summary(regresion1)
hipotesis2 = formula(DesigualdadGenero ~ factor3)
regresion2=lm(hipotesis2,data=subdata)
summary(regresion2)
hipotesis3 = formula(DesigualdadGenero ~ factor1 + factor2 + factor3)
regresion3=lm(hipotesis3,data=subdata[,-c(1)])
summary(regresion3)
# linea roja debe tender a horizontal
plot(regresion3, 1)
# linea roja debe tender a horizontal
plot(regresion3, 3)
library(lmtest)
# null: modelo homocedastico
bptest(regresion3)
# puntos cerca a la diagonal
plot(regresion3, 2)
shapiro.test(regresion3$residuals)
library(DescTools)
VIF(regresion3) # > 5 es problematico
